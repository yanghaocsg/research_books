# Reinforcement Learning

[TOC]



# 1  Reinforcement Learning Basic

-   Important points of RL
    -   和ML不同，不看训练集
    -   不是和data交互，而是和environment交互
    -   parameters从environment中来
    -   environment是2d,或者 3d
    -   RL 目标是goal
    -   Rewards从环境中来
-   ![1588410268539](1588410268539.png)
-   ![1588410298686](1588410298686.png)
-   ![1588410313736](1588410313736.png)
-   ![1588410384506](1588410384506.png)

## 1.1 Faces of Reinforcement Learning

-   ![1588410427285](1588410427285.png)

## 1.2 Flow of RL

![1588410518738](1588410518738.png)

![1588410542180](1588410542180.png)

![1588410590336](1588410590336.png)

## 1.3 Different Terms in RL

![1588410640995](1588410640995.png)

-   Gamma

    -   common in RL

-   Lambda

    -   temporal difference problems

    ![1588410711465](1588410711465.png)

    ![1588410742361](1588410742361.png)

    ![1588410756643](1588410756643.png)

    

## 1.4 Rewards如何起作用

​    

    -   Agent
    
    ![1588410815580](1588410815580.png)
    
    ## 1.5 Determinstic 确定性
    
    -   DFA 确定状态机
    -   ![1588410902049](1588410902049.png)
    -   NDFA
    -   ![1588410924689](1588410924689.png)
    -   单Agent
    -   ![1588410972024](1588410972024.png)
    -   多Agent
    -   ![1588410990803](1588410990803.png)


​    

# 2 RL 理论和算法

    -   MDP: markov decision process (马尔科夫决策过程)
    
    ![1588411085760](1588411085760.png)
    
     ![1588411148868](1588411148868.png)

![1588411183505](1588411183505.png)

-   enviroments	

    -   python
    -   conda
    -   docker
    -   ![1588411607210](1588411607210.png)
    -   ![1588411629266](1588411629266.png)
    -   ![1588411721754](1588411721754.png)
    -   ![1588411923202](1588411923202.png)
    -   ![1588411977226](1588411977226.png)
    -   ![1588412114367](1588412114367.png)
    -   ![1588412128514](1588412128514.png)
    -   ![1588412201465](1588412201465.png)
    -   ![1588412214726](1588412214726.png)
    -   ![1588412225550](1588412225550.png)
    -   ![1588412258672](1588412258672.png)

## 2.1 SARSA (State Action Reward next State and next Action)

     ![1588412438562](1588412438562.png) 

![1588422540389](1588422540389.png)

![1588422601085](1588422601085.png)

## 2.2 什么是Q

![1588422702410](1588422702410.png)

-   怎么用Q
-   ![1588422785865](1588422785865.png)
-   ![1588422807103](1588422807103.png)
-   ![1588422862536](1588422862536.png)
-   ![1588422904577](1588422904577.png)

## 2.3 动态规划

![1588423018415](1588423018415.png)

# 3 OpenAI 基础

![1588423625630](1588423625630.png)

![1588423712958](1588423712958.png)

![1588423731921](1588423731921.png)



![1588423760677](1588423760677.png)

## 3.1 安装 OpenAI Gym和 OpenAI Universe

![1588423802588](1588423802588.png)

## 3.2 使用OpenAI Gym 

![1588424292545](1588424292545.png)

![1588424346537](1588424346537.png)

## 3.3 更多模拟

![1588424402221](1588424402221.png)

## 3.4 OpenAI Universe

![1588424441604](1588424441604.png)

## 3.5 总结

-   OpenAI
-   OpenAI Gym
-   OpenAI Universe

# 4 用Python来进行强化学习

## 4.1 用python 进行QLearning

![1588424930211](1588424930211.png)

## 4.2 RL Brain

## 4.3 使用MDP 工具库

![1588425509490](1588425509490.png)

## 4.4 理解Swarm Intelligence (SI)

![1588425579726](1588425579726.png)

![1588425593758](1588425593758.png)

## 4.5 基于Ant的规划

![1588425646548](1588425646548.png)

![1588425668224](1588425668224.png)

## 4.6 构建 Game AI

## 4.7 总结

-   QLearning
-   MDP toolbox
-   swarm intelligence
-   game AI

# 5 用Keras, TF, ChainerRL进行强化深度学习

## 5.1 Keras

![1588425818992](1588425818992.png)

## 5.2 Keras 做RL

-   python
-   keras
-   pygame
-   scikit-image

## 5.3 用Chainer RL

![1588425894784](1588425894784.png)

![1588425913864](1588425913864.png)

## 5.4 用Keras, TF进行QLearning （Keras-RL)

![1588425959471](1588425959471.png)

# 6 Google DeepMind和RL的未来

## 6.1 Google DeepMind

![1588426035541](1588426035541.png)

![1588426045461](1588426045461.png)

![1588426057895](1588426057895.png)

![1588426067791](1588426067791.png)

## 6.2 Monte Carlo Search

![1588426092142](1588426092142.png)

## 6.3 Human VS Machine

![1588426123465](1588426123465.png)



