{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AverageMeter(object):\n",
    "    \"\"\"Computes and stores the average and current value\"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "        self.reset()\n",
    "\n",
    "    def reset(self):\n",
    "        self.val = 0\n",
    "        self.avg = 0\n",
    "        self.sum = 0\n",
    "        self.count = 0\n",
    "\n",
    "    def update(self, val, n=1):\n",
    "        self.val = val\n",
    "        self.sum += val * n\n",
    "        self.count += n\n",
    "        self.avg = self.sum / self.count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import torch\n",
    "DEVICE = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "def CORAL(source, target):\n",
    "    d = source.size(1)\n",
    "    ns, nt = source.size(0), target.size(0)\n",
    "\n",
    "    # source covariance\n",
    "    tmp_s = torch.ones((1, ns)).to(DEVICE) @ source\n",
    "    cs = (source.t() @ source - (tmp_s.t() @ tmp_s) / ns) / (ns - 1)\n",
    "\n",
    "    # target covariance\n",
    "    tmp_t = torch.ones((1, nt)).to(DEVICE) @ target\n",
    "    ct = (target.t() @ target - (tmp_t.t() @ tmp_t) / nt) / (nt - 1)\n",
    "\n",
    "    # frobenius norm\n",
    "    loss = (cs - ct).pow(2).sum().sqrt()\n",
    "    loss = loss / (4 * d * d)\n",
    "\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "print(DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision\n",
    "from torchvision import models\n",
    "from torch.autograd import Variable\n",
    "\n",
    "\n",
    "# convnet without the last layer\n",
    "class AlexNetFc(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(AlexNetFc, self).__init__()\n",
    "        model_alexnet = models.alexnet(pretrained=True)\n",
    "        self.features = model_alexnet.features\n",
    "        self.classifier = nn.Sequential()\n",
    "        for i in range(6):\n",
    "            self.classifier.add_module(\n",
    "                \"classifier\"+str(i), model_alexnet.classifier[i])\n",
    "        self.__in_features = model_alexnet.classifier[6].in_features\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.features(x)\n",
    "        x = x.view(x.size(0), 256*6*6)\n",
    "        x = self.classifier(x)\n",
    "        return x\n",
    "\n",
    "    def output_num(self):\n",
    "        return self.__in_features\n",
    "\n",
    "\n",
    "class ResNet18Fc(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(ResNet18Fc, self).__init__()\n",
    "        model_resnet18 = models.resnet18(pretrained=True)\n",
    "        self.conv1 = model_resnet18.conv1\n",
    "        self.bn1 = model_resnet18.bn1\n",
    "        self.relu = model_resnet18.relu\n",
    "        self.maxpool = model_resnet18.maxpool\n",
    "        self.layer1 = model_resnet18.layer1\n",
    "        self.layer2 = model_resnet18.layer2\n",
    "        self.layer3 = model_resnet18.layer3\n",
    "        self.layer4 = model_resnet18.layer4\n",
    "        self.avgpool = model_resnet18.avgpool\n",
    "        self.__in_features = model_resnet18.fc.in_features\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.bn1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.maxpool(x)\n",
    "        x = self.layer1(x)\n",
    "        x = self.layer2(x)\n",
    "        x = self.layer3(x)\n",
    "        x = self.layer4(x)\n",
    "        x = self.avgpool(x)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        return x\n",
    "\n",
    "    def output_num(self):\n",
    "        return self.__in_features\n",
    "\n",
    "\n",
    "class ResNet34Fc(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(ResNet34Fc, self).__init__()\n",
    "        model_resnet34 = models.resnet34(pretrained=True)\n",
    "        self.conv1 = model_resnet34.conv1\n",
    "        self.bn1 = model_resnet34.bn1\n",
    "        self.relu = model_resnet34.relu\n",
    "        self.maxpool = model_resnet34.maxpool\n",
    "        self.layer1 = model_resnet34.layer1\n",
    "        self.layer2 = model_resnet34.layer2\n",
    "        self.layer3 = model_resnet34.layer3\n",
    "        self.layer4 = model_resnet34.layer4\n",
    "        self.avgpool = model_resnet34.avgpool\n",
    "        self.__in_features = model_resnet34.fc.in_features\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.bn1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.maxpool(x)\n",
    "        x = self.layer1(x)\n",
    "        x = self.layer2(x)\n",
    "        x = self.layer3(x)\n",
    "        x = self.layer4(x)\n",
    "        x = self.avgpool(x)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        return x\n",
    "\n",
    "    def output_num(self):\n",
    "        return self.__in_features\n",
    "\n",
    "\n",
    "class ResNet50Fc(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(ResNet50Fc, self).__init__()\n",
    "        model_resnet50 = models.resnet50(pretrained=True)\n",
    "        self.conv1 = model_resnet50.conv1\n",
    "        self.bn1 = model_resnet50.bn1\n",
    "        self.relu = model_resnet50.relu\n",
    "        self.maxpool = model_resnet50.maxpool\n",
    "        self.layer1 = model_resnet50.layer1\n",
    "        self.layer2 = model_resnet50.layer2\n",
    "        self.layer3 = model_resnet50.layer3\n",
    "        self.layer4 = model_resnet50.layer4\n",
    "        self.avgpool = model_resnet50.avgpool\n",
    "        self.__in_features = model_resnet50.fc.in_features\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.bn1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.maxpool(x)\n",
    "        x = self.layer1(x)\n",
    "        x = self.layer2(x)\n",
    "        x = self.layer3(x)\n",
    "        x = self.layer4(x)\n",
    "        x = self.avgpool(x)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        return x\n",
    "\n",
    "    def output_num(self):\n",
    "        return self.__in_features\n",
    "\n",
    "\n",
    "class ResNet101Fc(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(ResNet101Fc, self).__init__()\n",
    "        model_resnet101 = models.resnet101(pretrained=True)\n",
    "        self.conv1 = model_resnet101.conv1\n",
    "        self.bn1 = model_resnet101.bn1\n",
    "        self.relu = model_resnet101.relu\n",
    "        self.maxpool = model_resnet101.maxpool\n",
    "        self.layer1 = model_resnet101.layer1\n",
    "        self.layer2 = model_resnet101.layer2\n",
    "        self.layer3 = model_resnet101.layer3\n",
    "        self.layer4 = model_resnet101.layer4\n",
    "        self.avgpool = model_resnet101.avgpool\n",
    "        self.__in_features = model_resnet101.fc.in_features\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.bn1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.maxpool(x)\n",
    "        x = self.layer1(x)\n",
    "        x = self.layer2(x)\n",
    "        x = self.layer3(x)\n",
    "        x = self.layer4(x)\n",
    "        x = self.avgpool(x)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        return x\n",
    "\n",
    "    def output_num(self):\n",
    "        return self.__in_features\n",
    "\n",
    "\n",
    "class ResNet152Fc(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(ResNet152Fc, self).__init__()\n",
    "        model_resnet152 = models.resnet152(pretrained=True)\n",
    "        self.conv1 = model_resnet152.conv1\n",
    "        self.bn1 = model_resnet152.bn1\n",
    "        self.relu = model_resnet152.relu\n",
    "        self.maxpool = model_resnet152.maxpool\n",
    "        self.layer1 = model_resnet152.layer1\n",
    "        self.layer2 = model_resnet152.layer2\n",
    "        self.layer3 = model_resnet152.layer3\n",
    "        self.layer4 = model_resnet152.layer4\n",
    "        self.avgpool = model_resnet152.avgpool\n",
    "        self.__in_features = model_resnet152.fc.in_features\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.bn1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.maxpool(x)\n",
    "        x = self.layer1(x)\n",
    "        x = self.layer2(x)\n",
    "        x = self.layer3(x)\n",
    "        x = self.layer4(x)\n",
    "        x = self.avgpool(x)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        return x\n",
    "\n",
    "    def output_num(self):\n",
    "        return self.__in_features\n",
    "\n",
    "\n",
    "network_dict = {\"alexnet\": AlexNetFc,\n",
    "                \"resnet18\": ResNet18Fc,\n",
    "                \"resnet34\": ResNet34Fc,\n",
    "                \"resnet50\": ResNet50Fc,\n",
    "                \"resnet101\": ResNet101Fc,\n",
    "                \"resnet152\": ResNet152Fc}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'alexnet': <class '__main__.AlexNetFc'>, 'resnet18': <class '__main__.ResNet18Fc'>, 'resnet34': <class '__main__.ResNet34Fc'>, 'resnet50': <class '__main__.ResNet50Fc'>, 'resnet101': <class '__main__.ResNet101Fc'>, 'resnet152': <class '__main__.ResNet152Fc'>} <class '__main__.ResNet34Fc'>\n"
     ]
    }
   ],
   "source": [
    "print(network_dict, network_dict['resnet34'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "CFG = {\n",
    "    'data_path': 'office31/',\n",
    "    'kwargs': {'num_workers': 4},\n",
    "    'batch_size': 24,\n",
    "    'epoch': 100,\n",
    "    'lr': 1e-3,\n",
    "    'momentum': .9,\n",
    "    'log_interval': 10,\n",
    "    'l2_decay': 0,\n",
    "    'lambda': 10,\n",
    "    'backbone': 'alexnet',\n",
    "    'n_class': 31,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mmd\n",
    "import torch\n",
    "\n",
    "\n",
    "class MMD_loss(nn.Module):\n",
    "    def __init__(self, kernel_type='rbf', kernel_mul=2.0, kernel_num=5):\n",
    "        super(MMD_loss, self).__init__()\n",
    "        self.kernel_num = kernel_num\n",
    "        self.kernel_mul = kernel_mul\n",
    "        self.fix_sigma = None\n",
    "        self.kernel_type = kernel_type\n",
    "\n",
    "    def guassian_kernel(self, source, target, kernel_mul=2.0, kernel_num=5, fix_sigma=None):\n",
    "        n_samples = int(source.size()[0]) + int(target.size()[0])\n",
    "        total = torch.cat([source, target], dim=0)\n",
    "        total0 = total.unsqueeze(0).expand(\n",
    "            int(total.size(0)), int(total.size(0)), int(total.size(1)))\n",
    "        total1 = total.unsqueeze(1).expand(\n",
    "            int(total.size(0)), int(total.size(0)), int(total.size(1)))\n",
    "        L2_distance = ((total0-total1)**2).sum(2)\n",
    "        if fix_sigma:\n",
    "            bandwidth = fix_sigma\n",
    "        else:\n",
    "            bandwidth = torch.sum(L2_distance.data) / (n_samples**2-n_samples)\n",
    "        bandwidth /= kernel_mul ** (kernel_num // 2)\n",
    "        bandwidth_list = [bandwidth * (kernel_mul**i)\n",
    "                          for i in range(kernel_num)]\n",
    "        kernel_val = [torch.exp(-L2_distance / bandwidth_temp)\n",
    "                      for bandwidth_temp in bandwidth_list]\n",
    "        return sum(kernel_val)\n",
    "\n",
    "    def linear_mmd2(self, f_of_X, f_of_Y):\n",
    "        loss = 0.0\n",
    "        delta = f_of_X.float().mean(0) - f_of_Y.float().mean(0)\n",
    "        loss = delta.dot(delta.T)\n",
    "        return loss\n",
    "\n",
    "    def forward(self, source, target):\n",
    "        if self.kernel_type == 'linear':\n",
    "            return self.linear_mmd2(source, target)\n",
    "        elif self.kernel_type == 'rbf':\n",
    "            batch_size = int(source.size()[0])\n",
    "            kernels = self.guassian_kernel(\n",
    "                source, target, kernel_mul=self.kernel_mul, kernel_num=self.kernel_num, fix_sigma=self.fix_sigma)\n",
    "            with torch.no_grad():\n",
    "                XX = torch.mean(kernels[:batch_size, :batch_size])\n",
    "                YY = torch.mean(kernels[batch_size:, batch_size:])\n",
    "                XY = torch.mean(kernels[:batch_size, batch_size:])\n",
    "                YX = torch.mean(kernels[batch_size:, :batch_size])\n",
    "                loss = torch.mean(XX + YY - XY - YX)\n",
    "            torch.cuda.empty_cache()\n",
    "            return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision\n",
    "\n",
    "\n",
    "class Transfer_Net(nn.Module):\n",
    "    def __init__(self, num_class, base_net='resnet50', transfer_loss='mmd', use_bottleneck=True, bottleneck_width=256, width=1024):\n",
    "        super(Transfer_Net, self).__init__()\n",
    "        self.base_network = network_dict[base_net]()\n",
    "        self.use_bottleneck = use_bottleneck\n",
    "        self.transfer_loss = transfer_loss\n",
    "        bottleneck_list = [nn.Linear(self.base_network.output_num(\n",
    "        ), bottleneck_width), nn.BatchNorm1d(bottleneck_width), nn.ReLU(), nn.Dropout(0.5)]\n",
    "        self.bottleneck_layer = nn.Sequential(*bottleneck_list)\n",
    "        classifier_layer_list = [nn.Linear(self.base_network.output_num(), width), nn.ReLU(), nn.Dropout(0.5),\n",
    "                                 nn.Linear(width, num_class)]\n",
    "        self.classifier_layer = nn.Sequential(*classifier_layer_list)\n",
    "\n",
    "        self.bottleneck_layer[0].weight.data.normal_(0, 0.005)\n",
    "        self.bottleneck_layer[0].bias.data.fill_(0.1)\n",
    "        for i in range(2):\n",
    "            self.classifier_layer[i * 3].weight.data.normal_(0, 0.01)\n",
    "            self.classifier_layer[i * 3].bias.data.fill_(0.0)\n",
    "\n",
    "    def forward(self, source, target):\n",
    "        source = self.base_network(source)\n",
    "        target = self.base_network(target)\n",
    "        source_clf = self.classifier_layer(source)\n",
    "        if self.use_bottleneck:\n",
    "            source = self.bottleneck_layer(source)\n",
    "            target = self.bottleneck_layer(target)\n",
    "        transfer_loss = self.adapt_loss(source, target, self.transfer_loss)\n",
    "        return source_clf, transfer_loss\n",
    "\n",
    "    def predict(self, x):\n",
    "        features = self.base_network(x)\n",
    "        clf = self.classifier_layer(features)\n",
    "        return clf\n",
    "\n",
    "    def adapt_loss(self, X, Y, adapt_loss):\n",
    "        \"\"\"Compute adaptation loss, currently we support mmd and coral\n",
    "        Arguments:\n",
    "            X {tensor} -- source matrix\n",
    "            Y {tensor} -- target matrix\n",
    "            adapt_loss {string} -- loss type, 'mmd' or 'coral'. You can add your own loss\n",
    "        Returns:\n",
    "            [tensor] -- adaptation loss tensor\n",
    "        \"\"\"\n",
    "        if adapt_loss == 'mmd':\n",
    "            mmd_loss = MMD_loss()\n",
    "            loss = mmd_loss(X, Y)\n",
    "        elif adapt_loss == 'coral':\n",
    "            loss = CORAL(X, Y)\n",
    "        else:\n",
    "            loss = 0\n",
    "        return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_ = Transfer_Net(CFG['n_class'], transfer_loss='mmd', base_net='resnet50').to(DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision import datasets, transforms\n",
    "def load_data_img(data_folder, batch_size, train, kwargs):\n",
    "    transform = {\n",
    "        'train': transforms.Compose(\n",
    "            [transforms.Resize([256, 256]),\n",
    "                transforms.RandomCrop(224),\n",
    "                transforms.RandomHorizontalFlip(),\n",
    "                transforms.ToTensor(),\n",
    "                transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                                  std=[0.229, 0.224, 0.225])]),\n",
    "        'test': transforms.Compose(\n",
    "            [transforms.Resize([224, 224]),\n",
    "                transforms.ToTensor(),\n",
    "                transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                                  std=[0.229, 0.224, 0.225])])\n",
    "        }\n",
    "    data = datasets.ImageFolder(root = data_folder, transform=transform['train' if train else 'test'])\n",
    "    data_loader = torch.utils.data.DataLoader(data, batch_size=batch_size, shuffle=True, **kwargs, drop_last = True if train else False)\n",
    "    return data_loader\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[[2.2489, 2.2489, 2.2489,  ..., 2.2489, 2.2489, 2.2489],\n",
      "          [2.2489, 2.2489, 2.2489,  ..., 2.2489, 2.2489, 2.2489],\n",
      "          [2.2489, 2.2489, 2.2489,  ..., 2.2489, 2.2489, 2.2489],\n",
      "          ...,\n",
      "          [2.2489, 2.2489, 2.2489,  ..., 2.2489, 2.2489, 2.2489],\n",
      "          [2.2489, 2.2489, 2.2489,  ..., 2.2489, 2.2489, 2.2489],\n",
      "          [2.2489, 2.2489, 2.2489,  ..., 2.2489, 2.2489, 2.2489]],\n",
      "\n",
      "         [[2.4286, 2.4286, 2.4286,  ..., 2.4111, 2.4111, 2.4111],\n",
      "          [2.4286, 2.4286, 2.4286,  ..., 2.4111, 2.4111, 2.4111],\n",
      "          [2.4286, 2.4286, 2.4286,  ..., 2.3936, 2.4111, 2.4111],\n",
      "          ...,\n",
      "          [2.4286, 2.4286, 2.4286,  ..., 2.4286, 2.4286, 2.4286],\n",
      "          [2.4286, 2.4286, 2.4286,  ..., 2.4286, 2.4286, 2.4286],\n",
      "          [2.4286, 2.4286, 2.4286,  ..., 2.4286, 2.4286, 2.4286]],\n",
      "\n",
      "         [[2.6400, 2.6400, 2.6400,  ..., 2.6400, 2.6400, 2.6400],\n",
      "          [2.6400, 2.6400, 2.6400,  ..., 2.6400, 2.6400, 2.6400],\n",
      "          [2.6400, 2.6400, 2.6400,  ..., 2.6226, 2.6400, 2.6400],\n",
      "          ...,\n",
      "          [2.6400, 2.6400, 2.6400,  ..., 2.6400, 2.6400, 2.6400],\n",
      "          [2.6400, 2.6400, 2.6400,  ..., 2.6400, 2.6400, 2.6400],\n",
      "          [2.6400, 2.6400, 2.6400,  ..., 2.6400, 2.6400, 2.6400]]],\n",
      "\n",
      "\n",
      "        [[[2.2489, 2.2489, 2.2489,  ..., 2.2489, 2.2489, 2.2489],\n",
      "          [2.2489, 2.2489, 2.2489,  ..., 2.2489, 2.2489, 2.2489],\n",
      "          [2.2489, 2.2489, 2.2489,  ..., 2.2489, 2.2489, 2.2489],\n",
      "          ...,\n",
      "          [2.2489, 2.2489, 2.2489,  ..., 2.2489, 2.2489, 2.2489],\n",
      "          [2.2489, 2.2489, 2.2489,  ..., 2.2489, 2.2489, 2.2489],\n",
      "          [2.2489, 2.2489, 2.2489,  ..., 2.2489, 2.2489, 2.2489]],\n",
      "\n",
      "         [[2.4286, 2.4286, 2.4286,  ..., 2.4286, 2.4286, 2.4286],\n",
      "          [2.4286, 2.4286, 2.4286,  ..., 2.4286, 2.4286, 2.4286],\n",
      "          [2.4286, 2.4286, 2.4286,  ..., 2.4286, 2.4286, 2.4286],\n",
      "          ...,\n",
      "          [2.4286, 2.4286, 2.4286,  ..., 2.4286, 2.4286, 2.4286],\n",
      "          [2.4286, 2.4286, 2.4286,  ..., 2.4286, 2.4286, 2.4286],\n",
      "          [2.4286, 2.4286, 2.4286,  ..., 2.4286, 2.4286, 2.4286]],\n",
      "\n",
      "         [[2.6400, 2.6400, 2.6400,  ..., 2.6400, 2.6400, 2.6400],\n",
      "          [2.6400, 2.6400, 2.6400,  ..., 2.6400, 2.6400, 2.6400],\n",
      "          [2.6400, 2.6400, 2.6400,  ..., 2.6400, 2.6400, 2.6400],\n",
      "          ...,\n",
      "          [2.6400, 2.6400, 2.6400,  ..., 2.6400, 2.6400, 2.6400],\n",
      "          [2.6400, 2.6400, 2.6400,  ..., 2.6400, 2.6400, 2.6400],\n",
      "          [2.6400, 2.6400, 2.6400,  ..., 2.6400, 2.6400, 2.6400]]],\n",
      "\n",
      "\n",
      "        [[[2.2489, 2.2489, 2.2489,  ..., 2.2489, 2.2489, 2.2489],\n",
      "          [2.2489, 2.2489, 2.2489,  ..., 2.2489, 2.2489, 2.2489],\n",
      "          [2.2489, 2.2489, 2.2489,  ..., 2.2489, 2.2489, 2.2489],\n",
      "          ...,\n",
      "          [2.2489, 2.2489, 2.2489,  ..., 2.2489, 2.2489, 2.2489],\n",
      "          [2.2489, 2.2489, 2.2489,  ..., 2.2489, 2.2489, 2.2489],\n",
      "          [2.2489, 2.2489, 2.2489,  ..., 2.2489, 2.2489, 2.2489]],\n",
      "\n",
      "         [[2.4286, 2.4286, 2.4286,  ..., 2.4286, 2.4286, 2.4286],\n",
      "          [2.4286, 2.4286, 2.4286,  ..., 2.4286, 2.4286, 2.4286],\n",
      "          [2.4286, 2.4286, 2.4286,  ..., 2.4286, 2.4286, 2.4286],\n",
      "          ...,\n",
      "          [2.4286, 2.4286, 2.4286,  ..., 2.4286, 2.4286, 2.4286],\n",
      "          [2.4286, 2.4286, 2.4286,  ..., 2.4286, 2.4286, 2.4286],\n",
      "          [2.4286, 2.4286, 2.4286,  ..., 2.4286, 2.4286, 2.4286]],\n",
      "\n",
      "         [[2.6400, 2.6400, 2.6400,  ..., 2.6400, 2.6400, 2.6400],\n",
      "          [2.6400, 2.6400, 2.6400,  ..., 2.6400, 2.6400, 2.6400],\n",
      "          [2.6400, 2.6400, 2.6400,  ..., 2.6400, 2.6400, 2.6400],\n",
      "          ...,\n",
      "          [2.6400, 2.6400, 2.6400,  ..., 2.6400, 2.6400, 2.6400],\n",
      "          [2.6400, 2.6400, 2.6400,  ..., 2.6400, 2.6400, 2.6400],\n",
      "          [2.6400, 2.6400, 2.6400,  ..., 2.6400, 2.6400, 2.6400]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[2.2489, 2.2489, 2.2489,  ..., 2.2489, 2.2489, 2.2489],\n",
      "          [2.2489, 2.2489, 2.2489,  ..., 2.2489, 2.2489, 2.2489],\n",
      "          [2.2489, 2.2489, 2.2489,  ..., 2.2489, 2.2489, 2.2489],\n",
      "          ...,\n",
      "          [2.2489, 2.2489, 2.2489,  ..., 2.2489, 2.2489, 2.2489],\n",
      "          [2.2489, 2.2489, 2.2489,  ..., 2.2489, 2.2489, 2.2489],\n",
      "          [2.2489, 2.2489, 2.2489,  ..., 2.2489, 2.2489, 2.2489]],\n",
      "\n",
      "         [[2.4286, 2.4286, 2.4286,  ..., 2.4286, 2.4286, 2.4286],\n",
      "          [2.4286, 2.4286, 2.4286,  ..., 2.4286, 2.4286, 2.4286],\n",
      "          [2.4286, 2.4286, 2.4286,  ..., 2.4286, 2.4286, 2.4286],\n",
      "          ...,\n",
      "          [2.4286, 2.4286, 2.4286,  ..., 2.4286, 2.4286, 2.4286],\n",
      "          [2.4286, 2.4286, 2.4286,  ..., 2.4286, 2.4286, 2.4286],\n",
      "          [2.4286, 2.4286, 2.4286,  ..., 2.4286, 2.4286, 2.4286]],\n",
      "\n",
      "         [[2.6400, 2.6400, 2.6400,  ..., 2.6400, 2.6400, 2.6400],\n",
      "          [2.6400, 2.6400, 2.6400,  ..., 2.6400, 2.6400, 2.6400],\n",
      "          [2.6400, 2.6400, 2.6400,  ..., 2.6400, 2.6400, 2.6400],\n",
      "          ...,\n",
      "          [2.6400, 2.6400, 2.6400,  ..., 2.6400, 2.6400, 2.6400],\n",
      "          [2.6400, 2.6400, 2.6400,  ..., 2.6400, 2.6400, 2.6400],\n",
      "          [2.6400, 2.6400, 2.6400,  ..., 2.6400, 2.6400, 2.6400]]],\n",
      "\n",
      "\n",
      "        [[[2.2489, 2.2489, 2.2489,  ..., 2.2489, 2.2489, 2.2489],\n",
      "          [2.2489, 2.2489, 2.2489,  ..., 2.2489, 2.2489, 2.2489],\n",
      "          [2.2489, 2.2489, 2.2489,  ..., 2.2489, 2.2489, 2.2489],\n",
      "          ...,\n",
      "          [2.2489, 2.2489, 2.2489,  ..., 2.2489, 2.2489, 2.2489],\n",
      "          [2.2489, 2.2489, 2.2489,  ..., 2.2489, 2.2489, 2.2489],\n",
      "          [2.2489, 2.2489, 2.2489,  ..., 2.2489, 2.2489, 2.2489]],\n",
      "\n",
      "         [[2.4286, 2.4286, 2.4286,  ..., 2.4286, 2.4286, 2.4286],\n",
      "          [2.4286, 2.4286, 2.4286,  ..., 2.4286, 2.4286, 2.4286],\n",
      "          [2.4286, 2.4286, 2.4286,  ..., 2.4286, 2.4286, 2.4286],\n",
      "          ...,\n",
      "          [2.4286, 2.4286, 2.4286,  ..., 2.4286, 2.4286, 2.4286],\n",
      "          [2.4286, 2.4286, 2.4286,  ..., 2.4286, 2.4286, 2.4286],\n",
      "          [2.4286, 2.4286, 2.4286,  ..., 2.4286, 2.4286, 2.4286]],\n",
      "\n",
      "         [[2.6400, 2.6400, 2.6400,  ..., 2.6400, 2.6400, 2.6400],\n",
      "          [2.6400, 2.6400, 2.6400,  ..., 2.6400, 2.6400, 2.6400],\n",
      "          [2.6400, 2.6400, 2.6400,  ..., 2.6400, 2.6400, 2.6400],\n",
      "          ...,\n",
      "          [2.6400, 2.6400, 2.6400,  ..., 2.6400, 2.6400, 2.6400],\n",
      "          [2.6400, 2.6400, 2.6400,  ..., 2.6400, 2.6400, 2.6400],\n",
      "          [2.6400, 2.6400, 2.6400,  ..., 2.6400, 2.6400, 2.6400]]],\n",
      "\n",
      "\n",
      "        [[[2.2489, 2.2489, 2.2489,  ..., 2.2489, 2.2489, 2.2489],\n",
      "          [2.2489, 2.2489, 2.2489,  ..., 2.2489, 2.2489, 2.2489],\n",
      "          [2.2489, 2.2489, 2.2489,  ..., 2.2489, 2.2489, 2.2489],\n",
      "          ...,\n",
      "          [2.2489, 2.2489, 2.2489,  ..., 2.2489, 2.2489, 2.2489],\n",
      "          [2.2489, 2.2489, 2.2489,  ..., 2.2489, 2.2489, 2.2489],\n",
      "          [2.2489, 2.2489, 2.2489,  ..., 2.2489, 2.2489, 2.2489]],\n",
      "\n",
      "         [[2.4286, 2.4286, 2.4286,  ..., 2.4286, 2.4286, 2.4286],\n",
      "          [2.4286, 2.4286, 2.4286,  ..., 2.4286, 2.4286, 2.4286],\n",
      "          [2.4286, 2.4286, 2.4286,  ..., 2.4286, 2.4286, 2.4286],\n",
      "          ...,\n",
      "          [2.4286, 2.4286, 2.4286,  ..., 2.4286, 2.4286, 2.4286],\n",
      "          [2.4286, 2.4286, 2.4286,  ..., 2.4286, 2.4286, 2.4286],\n",
      "          [2.4286, 2.4286, 2.4286,  ..., 2.4286, 2.4286, 2.4286]],\n",
      "\n",
      "         [[2.6400, 2.6400, 2.6400,  ..., 2.6400, 2.6400, 2.6400],\n",
      "          [2.6400, 2.6400, 2.6400,  ..., 2.6400, 2.6400, 2.6400],\n",
      "          [2.6400, 2.6400, 2.6400,  ..., 2.6400, 2.6400, 2.6400],\n",
      "          ...,\n",
      "          [2.6400, 2.6400, 2.6400,  ..., 2.6400, 2.6400, 2.6400],\n",
      "          [2.6400, 2.6400, 2.6400,  ..., 2.6400, 2.6400, 2.6400],\n",
      "          [2.6400, 2.6400, 2.6400,  ..., 2.6400, 2.6400, 2.6400]]]]) tensor([15, 27, 17,  6,  0, 21,  6, 20, 22, 26,  4, 25,  7, 23, 12, 26,  5, 24,\n",
      "         8, 13,  2, 30, 23, 26, 25, 29, 30,  3,  2, 22, 14, 19])\n",
      "torch.Size([32, 3, 224, 224]) torch.Size([32])\n"
     ]
    }
   ],
   "source": [
    "test_loader = load_data_img('office31/amazon/images/', 32, True,  CFG['kwargs'])\n",
    "for inputs_, labels_ in test_loader:\n",
    "    print(inputs_, labels_)\n",
    "    print(inputs_.shape, labels_.shape)\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<torch.utils.data.dataloader.DataLoader at 0x7fb86f181be0>,\n",
       " <torch.utils.data.dataloader.DataLoader at 0x7fb86f194a90>,\n",
       " <torch.utils.data.dataloader.DataLoader at 0x7fb86f194f60>)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "import os\n",
    "import math\n",
    "import numpy as np\n",
    "\n",
    "log=[]\n",
    "acc = []\n",
    "def test(model, target_test_loader):\n",
    "    model.eval()\n",
    "    test_loss = AverageMeter()\n",
    "    correct = 0\n",
    "    criterion = torch.nn.CrossEntropyLoss()\n",
    "    len_target_dataset = len(target_test_loader.dataset)\n",
    "    with torch.no_grad():\n",
    "        for data, target in target_test_loader:\n",
    "            data, target = data.to(DEVICE), target.to(DEVICE)\n",
    "            s_output = model.predict(data)\n",
    "            loss = criterion(s_output, target)\n",
    "            test_loss.update(loss.item())\n",
    "            pred = torch.max(s_output, 1)[1]\n",
    "            correct += torch.sum(pred == target)\n",
    "\n",
    "    print('{} --> {}: max correct: {}, accuracy{: .2f}%\\n'.format(\n",
    "        source_name, target_name, correct, 100. * correct / len_target_dataset))\n",
    "    acc.append([100 * correct / len_target_dataset, correct, len_target_dataset])\n",
    "\n",
    "\n",
    "def train(source_loader, target_train_loader, target_test_loader, model, optimizer, CFG):\n",
    "    len_source_loader = len(source_loader)\n",
    "    len_target_loader = len(target_train_loader)\n",
    "    for e in range(CFG['epoch']):\n",
    "        train_loss_clf = AverageMeter()\n",
    "        train_loss_transfer = AverageMeter()\n",
    "        train_loss_total = AverageMeter()\n",
    "        model.train()\n",
    "        iter_source, iter_target = iter(\n",
    "            source_loader), iter(target_train_loader)\n",
    "        n_batch = min(len_source_loader, len_target_loader)\n",
    "        criterion = torch.nn.CrossEntropyLoss()\n",
    "        for i in range(n_batch):\n",
    "            data_source, label_source = iter_source.next()\n",
    "            data_target, _ = iter_target.next()\n",
    "            data_source, label_source = data_source.to(\n",
    "                DEVICE), label_source.to(DEVICE)\n",
    "            data_target = data_target.to(DEVICE)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            label_source_pred, transfer_loss = model(data_source, data_target)\n",
    "            clf_loss = criterion(label_source_pred, label_source)\n",
    "            loss = clf_loss + CFG['lambda'] * transfer_loss\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            train_loss_clf.update(clf_loss.item())\n",
    "            train_loss_transfer.update(transfer_loss.item())\n",
    "            train_loss_total.update(loss.item())\n",
    "            if i % CFG['log_interval'] == 0:\n",
    "                print('Train Epoch: [{}/{} ({:02d}%)], cls_Loss: {:.6f}, transfer_loss: {:.6f}, total_Loss: {:.6f}'.format(\n",
    "                    e + 1,\n",
    "                    CFG['epoch'],\n",
    "                    int(100. * i / n_batch), train_loss_clf.avg, train_loss_transfer.avg, train_loss_total.avg))\n",
    "        log.append([train_loss_clf.avg, train_loss_transfer.avg, train_loss_total.avg])\n",
    "        np_log = np.array(log, dtype=float)\n",
    "        np.savetxt('train_log.csv', np_log, delimiter=',', fmt='%.6f')\n",
    "        # Test\n",
    "        test(model, target_test_loader)\n",
    "    \n",
    "\n",
    "def load_data(src, tar, root_dir):\n",
    "    folder_src = root_dir + src + '/images/'\n",
    "    folder_tar = root_dir + tar + '/images/'\n",
    "    source_loader = load_data_img(\n",
    "        folder_src, CFG['batch_size'], True, CFG['kwargs'])\n",
    "    target_train_loader = load_data_img(\n",
    "        folder_tar, CFG['batch_size'], True, CFG['kwargs'])\n",
    "    target_test_loader = load_data_img(\n",
    "        folder_tar, CFG['batch_size'], False, CFG['kwargs'])\n",
    "    return source_loader, target_train_loader, target_test_loader\n",
    "\n",
    "\n",
    "\n",
    "load_data('amazon', 'webcam', 'office31/')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Src: amazon, Tar: webcam\n"
     ]
    }
   ],
   "source": [
    "\n",
    "torch.manual_seed(0)\n",
    "\n",
    "source_name = \"amazon\"\n",
    "target_name = \"webcam\"\n",
    "\n",
    "print('Src: %s, Tar: %s' % (source_name, target_name))\n",
    "\n",
    "source_loader, target_train_loader, target_test_loader = load_data(source_name, target_name, CFG['data_path'])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: [1/100 (00%)], cls_Loss: 3.440253, transfer_loss: 0.212678, total_Loss: 5.567032\n",
      "Train Epoch: [1/100 (30%)], cls_Loss: 3.404644, transfer_loss: 0.213843, total_Loss: 5.543071\n",
      "Train Epoch: [1/100 (60%)], cls_Loss: 3.365681, transfer_loss: 0.215158, total_Loss: 5.517257\n",
      "Train Epoch: [1/100 (90%)], cls_Loss: 3.316082, transfer_loss: 0.215270, total_Loss: 5.468784\n",
      "amazon --> webcam: max correct: 221, accuracy 27.80%\n",
      "\n",
      "Train Epoch: [2/100 (00%)], cls_Loss: 2.836616, transfer_loss: 0.214170, total_Loss: 4.978311\n",
      "Train Epoch: [2/100 (30%)], cls_Loss: 2.812130, transfer_loss: 0.215378, total_Loss: 4.965913\n",
      "Train Epoch: [2/100 (60%)], cls_Loss: 2.619346, transfer_loss: 0.214964, total_Loss: 4.768982\n",
      "Train Epoch: [2/100 (90%)], cls_Loss: 2.428165, transfer_loss: 0.214500, total_Loss: 4.573161\n",
      "amazon --> webcam: max correct: 367, accuracy 46.16%\n",
      "\n",
      "Train Epoch: [3/100 (00%)], cls_Loss: 1.454873, transfer_loss: 0.210630, total_Loss: 3.561177\n",
      "Train Epoch: [3/100 (30%)], cls_Loss: 1.623422, transfer_loss: 0.215294, total_Loss: 3.776366\n",
      "Train Epoch: [3/100 (60%)], cls_Loss: 1.462930, transfer_loss: 0.215294, total_Loss: 3.615868\n",
      "Train Epoch: [3/100 (90%)], cls_Loss: 1.376239, transfer_loss: 0.215181, total_Loss: 3.528046\n",
      "amazon --> webcam: max correct: 454, accuracy 57.11%\n",
      "\n",
      "Train Epoch: [4/100 (00%)], cls_Loss: 1.716810, transfer_loss: 0.220157, total_Loss: 3.918377\n",
      "Train Epoch: [4/100 (30%)], cls_Loss: 1.075560, transfer_loss: 0.215485, total_Loss: 3.230407\n",
      "Train Epoch: [4/100 (60%)], cls_Loss: 1.036754, transfer_loss: 0.214405, total_Loss: 3.180799\n",
      "Train Epoch: [4/100 (90%)], cls_Loss: 1.034024, transfer_loss: 0.213743, total_Loss: 3.171452\n",
      "amazon --> webcam: max correct: 445, accuracy 55.97%\n",
      "\n",
      "Train Epoch: [5/100 (00%)], cls_Loss: 0.755109, transfer_loss: 0.210274, total_Loss: 2.857845\n",
      "Train Epoch: [5/100 (30%)], cls_Loss: 0.935816, transfer_loss: 0.213880, total_Loss: 3.074616\n",
      "Train Epoch: [5/100 (60%)], cls_Loss: 0.916855, transfer_loss: 0.214727, total_Loss: 3.064130\n",
      "Train Epoch: [5/100 (90%)], cls_Loss: 0.966992, transfer_loss: 0.214456, total_Loss: 3.111557\n",
      "amazon --> webcam: max correct: 563, accuracy 70.82%\n",
      "\n",
      "Train Epoch: [6/100 (00%)], cls_Loss: 0.751312, transfer_loss: 0.211618, total_Loss: 2.867488\n",
      "Train Epoch: [6/100 (30%)], cls_Loss: 0.749072, transfer_loss: 0.211703, total_Loss: 2.866102\n",
      "Train Epoch: [6/100 (60%)], cls_Loss: 0.734244, transfer_loss: 0.214455, total_Loss: 2.878793\n",
      "Train Epoch: [6/100 (90%)], cls_Loss: 0.749539, transfer_loss: 0.215353, total_Loss: 2.903070\n",
      "amazon --> webcam: max correct: 545, accuracy 68.55%\n",
      "\n",
      "Train Epoch: [7/100 (00%)], cls_Loss: 1.233936, transfer_loss: 0.217884, total_Loss: 3.412776\n",
      "Train Epoch: [7/100 (30%)], cls_Loss: 0.573188, transfer_loss: 0.211769, total_Loss: 2.690875\n",
      "Train Epoch: [7/100 (60%)], cls_Loss: 0.612839, transfer_loss: 0.212577, total_Loss: 2.738614\n",
      "Train Epoch: [7/100 (90%)], cls_Loss: 0.667453, transfer_loss: 0.214086, total_Loss: 2.808310\n",
      "amazon --> webcam: max correct: 557, accuracy 70.06%\n",
      "\n",
      "Train Epoch: [8/100 (00%)], cls_Loss: 1.461625, transfer_loss: 0.210668, total_Loss: 3.568301\n",
      "Train Epoch: [8/100 (30%)], cls_Loss: 0.662685, transfer_loss: 0.211113, total_Loss: 2.773814\n",
      "Train Epoch: [8/100 (60%)], cls_Loss: 0.640617, transfer_loss: 0.214180, total_Loss: 2.782419\n",
      "Train Epoch: [8/100 (90%)], cls_Loss: 0.582272, transfer_loss: 0.215177, total_Loss: 2.734039\n",
      "amazon --> webcam: max correct: 570, accuracy 71.70%\n",
      "\n",
      "Train Epoch: [9/100 (00%)], cls_Loss: 1.057806, transfer_loss: 0.216622, total_Loss: 3.224028\n",
      "Train Epoch: [9/100 (30%)], cls_Loss: 0.562886, transfer_loss: 0.212545, total_Loss: 2.688335\n",
      "Train Epoch: [9/100 (60%)], cls_Loss: 0.497311, transfer_loss: 0.213343, total_Loss: 2.630743\n",
      "Train Epoch: [9/100 (90%)], cls_Loss: 0.451019, transfer_loss: 0.213411, total_Loss: 2.585132\n",
      "amazon --> webcam: max correct: 587, accuracy 73.84%\n",
      "\n",
      "Train Epoch: [10/100 (00%)], cls_Loss: 0.566588, transfer_loss: 0.221150, total_Loss: 2.778091\n",
      "Train Epoch: [10/100 (30%)], cls_Loss: 0.483192, transfer_loss: 0.216455, total_Loss: 2.647739\n",
      "Train Epoch: [10/100 (60%)], cls_Loss: 0.529904, transfer_loss: 0.216197, total_Loss: 2.691877\n",
      "Train Epoch: [10/100 (90%)], cls_Loss: 0.534310, transfer_loss: 0.216081, total_Loss: 2.695121\n",
      "amazon --> webcam: max correct: 585, accuracy 73.58%\n",
      "\n",
      "Train Epoch: [11/100 (00%)], cls_Loss: 0.368483, transfer_loss: 0.220628, total_Loss: 2.574762\n",
      "Train Epoch: [11/100 (30%)], cls_Loss: 0.402833, transfer_loss: 0.216288, total_Loss: 2.565709\n",
      "Train Epoch: [11/100 (60%)], cls_Loss: 0.419599, transfer_loss: 0.216214, total_Loss: 2.581744\n",
      "Train Epoch: [11/100 (90%)], cls_Loss: 0.422068, transfer_loss: 0.216482, total_Loss: 2.586890\n",
      "amazon --> webcam: max correct: 575, accuracy 72.33%\n",
      "\n",
      "Train Epoch: [12/100 (00%)], cls_Loss: 0.066270, transfer_loss: 0.217456, total_Loss: 2.240826\n",
      "Train Epoch: [12/100 (30%)], cls_Loss: 0.397301, transfer_loss: 0.215259, total_Loss: 2.549888\n",
      "Train Epoch: [12/100 (60%)], cls_Loss: 0.485566, transfer_loss: 0.214466, total_Loss: 2.630228\n",
      "Train Epoch: [12/100 (90%)], cls_Loss: 0.476876, transfer_loss: 0.215060, total_Loss: 2.627478\n",
      "amazon --> webcam: max correct: 551, accuracy 69.31%\n",
      "\n",
      "Train Epoch: [13/100 (00%)], cls_Loss: 0.306213, transfer_loss: 0.224048, total_Loss: 2.546695\n",
      "Train Epoch: [13/100 (30%)], cls_Loss: 0.414351, transfer_loss: 0.215935, total_Loss: 2.573705\n",
      "Train Epoch: [13/100 (60%)], cls_Loss: 0.441939, transfer_loss: 0.214417, total_Loss: 2.586111\n",
      "Train Epoch: [13/100 (90%)], cls_Loss: 0.413430, transfer_loss: 0.214506, total_Loss: 2.558490\n",
      "amazon --> webcam: max correct: 589, accuracy 74.09%\n",
      "\n",
      "Train Epoch: [14/100 (00%)], cls_Loss: 0.132150, transfer_loss: 0.215349, total_Loss: 2.285637\n",
      "Train Epoch: [14/100 (30%)], cls_Loss: 0.282321, transfer_loss: 0.214936, total_Loss: 2.431679\n",
      "Train Epoch: [14/100 (60%)], cls_Loss: 0.297793, transfer_loss: 0.214812, total_Loss: 2.445911\n",
      "Train Epoch: [14/100 (90%)], cls_Loss: 0.306006, transfer_loss: 0.214579, total_Loss: 2.451794\n",
      "amazon --> webcam: max correct: 556, accuracy 69.94%\n",
      "\n",
      "Train Epoch: [15/100 (00%)], cls_Loss: 0.749082, transfer_loss: 0.215171, total_Loss: 2.900789\n",
      "Train Epoch: [15/100 (30%)], cls_Loss: 0.394200, transfer_loss: 0.213738, total_Loss: 2.531584\n",
      "Train Epoch: [15/100 (60%)], cls_Loss: 0.355535, transfer_loss: 0.215067, total_Loss: 2.506203\n",
      "Train Epoch: [15/100 (90%)], cls_Loss: 0.339733, transfer_loss: 0.216049, total_Loss: 2.500226\n",
      "amazon --> webcam: max correct: 547, accuracy 68.81%\n",
      "\n",
      "Train Epoch: [16/100 (00%)], cls_Loss: 0.078379, transfer_loss: 0.221733, total_Loss: 2.295714\n",
      "Train Epoch: [16/100 (30%)], cls_Loss: 0.319631, transfer_loss: 0.215120, total_Loss: 2.470833\n",
      "Train Epoch: [16/100 (60%)], cls_Loss: 0.342375, transfer_loss: 0.215173, total_Loss: 2.494104\n",
      "Train Epoch: [16/100 (90%)], cls_Loss: 0.329941, transfer_loss: 0.214812, total_Loss: 2.478059\n",
      "amazon --> webcam: max correct: 586, accuracy 73.71%\n",
      "\n",
      "Train Epoch: [17/100 (00%)], cls_Loss: 0.248302, transfer_loss: 0.210081, total_Loss: 2.349113\n",
      "Train Epoch: [17/100 (30%)], cls_Loss: 0.293860, transfer_loss: 0.216547, total_Loss: 2.459330\n",
      "Train Epoch: [17/100 (60%)], cls_Loss: 0.251949, transfer_loss: 0.216672, total_Loss: 2.418668\n",
      "Train Epoch: [17/100 (90%)], cls_Loss: 0.273134, transfer_loss: 0.215932, total_Loss: 2.432453\n",
      "amazon --> webcam: max correct: 613, accuracy 77.11%\n",
      "\n",
      "Train Epoch: [18/100 (00%)], cls_Loss: 0.179558, transfer_loss: 0.206315, total_Loss: 2.242703\n",
      "Train Epoch: [18/100 (30%)], cls_Loss: 0.267384, transfer_loss: 0.214457, total_Loss: 2.411952\n",
      "Train Epoch: [18/100 (60%)], cls_Loss: 0.259490, transfer_loss: 0.214599, total_Loss: 2.405484\n",
      "Train Epoch: [18/100 (90%)], cls_Loss: 0.243702, transfer_loss: 0.215425, total_Loss: 2.397950\n",
      "amazon --> webcam: max correct: 611, accuracy 76.86%\n",
      "\n",
      "Train Epoch: [19/100 (00%)], cls_Loss: 0.255197, transfer_loss: 0.209813, total_Loss: 2.353328\n",
      "Train Epoch: [19/100 (30%)], cls_Loss: 0.218213, transfer_loss: 0.213183, total_Loss: 2.350043\n",
      "Train Epoch: [19/100 (60%)], cls_Loss: 0.205259, transfer_loss: 0.214772, total_Loss: 2.352975\n",
      "Train Epoch: [19/100 (90%)], cls_Loss: 0.228438, transfer_loss: 0.215156, total_Loss: 2.380003\n",
      "amazon --> webcam: max correct: 608, accuracy 76.48%\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: [20/100 (00%)], cls_Loss: 0.197693, transfer_loss: 0.218181, total_Loss: 2.379507\n",
      "Train Epoch: [20/100 (30%)], cls_Loss: 0.247334, transfer_loss: 0.214142, total_Loss: 2.388749\n",
      "Train Epoch: [20/100 (60%)], cls_Loss: 0.254326, transfer_loss: 0.214135, total_Loss: 2.395681\n",
      "Train Epoch: [20/100 (90%)], cls_Loss: 0.224846, transfer_loss: 0.214480, total_Loss: 2.369643\n",
      "amazon --> webcam: max correct: 612, accuracy 76.98%\n",
      "\n",
      "Train Epoch: [21/100 (00%)], cls_Loss: 0.052140, transfer_loss: 0.223468, total_Loss: 2.286824\n",
      "Train Epoch: [21/100 (30%)], cls_Loss: 0.212320, transfer_loss: 0.215340, total_Loss: 2.365719\n",
      "Train Epoch: [21/100 (60%)], cls_Loss: 0.208259, transfer_loss: 0.215002, total_Loss: 2.358277\n",
      "Train Epoch: [21/100 (90%)], cls_Loss: 0.191653, transfer_loss: 0.215524, total_Loss: 2.346897\n",
      "amazon --> webcam: max correct: 573, accuracy 72.08%\n",
      "\n",
      "Train Epoch: [22/100 (00%)], cls_Loss: 0.220366, transfer_loss: 0.215786, total_Loss: 2.378230\n",
      "Train Epoch: [22/100 (30%)], cls_Loss: 0.235830, transfer_loss: 0.214527, total_Loss: 2.381095\n",
      "Train Epoch: [22/100 (60%)], cls_Loss: 0.228464, transfer_loss: 0.214745, total_Loss: 2.375916\n",
      "Train Epoch: [22/100 (90%)], cls_Loss: 0.212891, transfer_loss: 0.214623, total_Loss: 2.359120\n",
      "amazon --> webcam: max correct: 591, accuracy 74.34%\n",
      "\n",
      "Train Epoch: [23/100 (00%)], cls_Loss: 0.271220, transfer_loss: 0.218482, total_Loss: 2.456035\n",
      "Train Epoch: [23/100 (30%)], cls_Loss: 0.172163, transfer_loss: 0.213343, total_Loss: 2.305597\n",
      "Train Epoch: [23/100 (60%)], cls_Loss: 0.170379, transfer_loss: 0.214072, total_Loss: 2.311095\n",
      "Train Epoch: [23/100 (90%)], cls_Loss: 0.168759, transfer_loss: 0.213417, total_Loss: 2.302931\n",
      "amazon --> webcam: max correct: 580, accuracy 72.96%\n",
      "\n",
      "Train Epoch: [24/100 (00%)], cls_Loss: 0.136032, transfer_loss: 0.208596, total_Loss: 2.221993\n",
      "Train Epoch: [24/100 (30%)], cls_Loss: 0.145591, transfer_loss: 0.213962, total_Loss: 2.285207\n",
      "Train Epoch: [24/100 (60%)], cls_Loss: 0.155368, transfer_loss: 0.214095, total_Loss: 2.296320\n",
      "Train Epoch: [24/100 (90%)], cls_Loss: 0.166036, transfer_loss: 0.214302, total_Loss: 2.309053\n",
      "amazon --> webcam: max correct: 586, accuracy 73.71%\n",
      "\n",
      "Train Epoch: [25/100 (00%)], cls_Loss: 0.140952, transfer_loss: 0.221862, total_Loss: 2.359572\n",
      "Train Epoch: [25/100 (30%)], cls_Loss: 0.140060, transfer_loss: 0.215764, total_Loss: 2.297698\n",
      "Train Epoch: [25/100 (60%)], cls_Loss: 0.197863, transfer_loss: 0.215613, total_Loss: 2.353988\n",
      "Train Epoch: [25/100 (90%)], cls_Loss: 0.172830, transfer_loss: 0.214765, total_Loss: 2.320483\n",
      "amazon --> webcam: max correct: 571, accuracy 71.82%\n",
      "\n",
      "Train Epoch: [26/100 (00%)], cls_Loss: 0.039940, transfer_loss: 0.209910, total_Loss: 2.139037\n",
      "Train Epoch: [26/100 (30%)], cls_Loss: 0.168577, transfer_loss: 0.211788, total_Loss: 2.286453\n",
      "Train Epoch: [26/100 (60%)], cls_Loss: 0.161512, transfer_loss: 0.214006, total_Loss: 2.301573\n",
      "Train Epoch: [26/100 (90%)], cls_Loss: 0.153073, transfer_loss: 0.214155, total_Loss: 2.294624\n",
      "amazon --> webcam: max correct: 574, accuracy 72.20%\n",
      "\n",
      "Train Epoch: [27/100 (00%)], cls_Loss: 0.011341, transfer_loss: 0.217482, total_Loss: 2.186163\n",
      "Train Epoch: [27/100 (30%)], cls_Loss: 0.112159, transfer_loss: 0.214697, total_Loss: 2.259130\n",
      "Train Epoch: [27/100 (60%)], cls_Loss: 0.094097, transfer_loss: 0.213674, total_Loss: 2.230837\n",
      "Train Epoch: [27/100 (90%)], cls_Loss: 0.095534, transfer_loss: 0.213730, total_Loss: 2.232836\n",
      "amazon --> webcam: max correct: 591, accuracy 74.34%\n",
      "\n",
      "Train Epoch: [28/100 (00%)], cls_Loss: 0.044750, transfer_loss: 0.215757, total_Loss: 2.202321\n",
      "Train Epoch: [28/100 (30%)], cls_Loss: 0.154093, transfer_loss: 0.215134, total_Loss: 2.305436\n",
      "Train Epoch: [28/100 (60%)], cls_Loss: 0.127153, transfer_loss: 0.215369, total_Loss: 2.280843\n",
      "Train Epoch: [28/100 (90%)], cls_Loss: 0.145866, transfer_loss: 0.215244, total_Loss: 2.298307\n",
      "amazon --> webcam: max correct: 587, accuracy 73.84%\n",
      "\n",
      "Train Epoch: [29/100 (00%)], cls_Loss: 0.022382, transfer_loss: 0.205395, total_Loss: 2.076330\n",
      "Train Epoch: [29/100 (30%)], cls_Loss: 0.128056, transfer_loss: 0.215615, total_Loss: 2.284207\n",
      "Train Epoch: [29/100 (60%)], cls_Loss: 0.155161, transfer_loss: 0.215174, total_Loss: 2.306898\n",
      "Train Epoch: [29/100 (90%)], cls_Loss: 0.169182, transfer_loss: 0.215191, total_Loss: 2.321090\n",
      "amazon --> webcam: max correct: 570, accuracy 71.70%\n",
      "\n",
      "Train Epoch: [30/100 (00%)], cls_Loss: 0.175696, transfer_loss: 0.218597, total_Loss: 2.361669\n",
      "Train Epoch: [30/100 (30%)], cls_Loss: 0.124933, transfer_loss: 0.212360, total_Loss: 2.248533\n",
      "Train Epoch: [30/100 (60%)], cls_Loss: 0.151305, transfer_loss: 0.212443, total_Loss: 2.275731\n",
      "Train Epoch: [30/100 (90%)], cls_Loss: 0.154447, transfer_loss: 0.212809, total_Loss: 2.282539\n",
      "amazon --> webcam: max correct: 571, accuracy 71.82%\n",
      "\n",
      "Train Epoch: [31/100 (00%)], cls_Loss: 0.093176, transfer_loss: 0.225829, total_Loss: 2.351465\n",
      "Train Epoch: [31/100 (30%)], cls_Loss: 0.105716, transfer_loss: 0.215450, total_Loss: 2.260216\n",
      "Train Epoch: [31/100 (60%)], cls_Loss: 0.115792, transfer_loss: 0.214950, total_Loss: 2.265296\n",
      "Train Epoch: [31/100 (90%)], cls_Loss: 0.120821, transfer_loss: 0.215442, total_Loss: 2.275239\n",
      "amazon --> webcam: max correct: 588, accuracy 73.96%\n",
      "\n",
      "Train Epoch: [32/100 (00%)], cls_Loss: 0.010107, transfer_loss: 0.212059, total_Loss: 2.130699\n",
      "Train Epoch: [32/100 (30%)], cls_Loss: 0.110756, transfer_loss: 0.213644, total_Loss: 2.247198\n",
      "Train Epoch: [32/100 (60%)], cls_Loss: 0.101473, transfer_loss: 0.212418, total_Loss: 2.225656\n",
      "Train Epoch: [32/100 (90%)], cls_Loss: 0.104149, transfer_loss: 0.212474, total_Loss: 2.228890\n",
      "amazon --> webcam: max correct: 574, accuracy 72.20%\n",
      "\n",
      "Train Epoch: [33/100 (00%)], cls_Loss: 0.003363, transfer_loss: 0.220625, total_Loss: 2.209613\n",
      "Train Epoch: [33/100 (30%)], cls_Loss: 0.106077, transfer_loss: 0.213841, total_Loss: 2.244488\n",
      "Train Epoch: [33/100 (60%)], cls_Loss: 0.101133, transfer_loss: 0.215054, total_Loss: 2.251678\n",
      "Train Epoch: [33/100 (90%)], cls_Loss: 0.105088, transfer_loss: 0.214843, total_Loss: 2.253522\n",
      "amazon --> webcam: max correct: 566, accuracy 71.19%\n",
      "\n",
      "Train Epoch: [34/100 (00%)], cls_Loss: 0.180821, transfer_loss: 0.215915, total_Loss: 2.339973\n",
      "Train Epoch: [34/100 (30%)], cls_Loss: 0.102692, transfer_loss: 0.215299, total_Loss: 2.255685\n",
      "Train Epoch: [34/100 (60%)], cls_Loss: 0.125656, transfer_loss: 0.214222, total_Loss: 2.267876\n",
      "Train Epoch: [34/100 (90%)], cls_Loss: 0.140353, transfer_loss: 0.214093, total_Loss: 2.281284\n",
      "amazon --> webcam: max correct: 601, accuracy 75.60%\n",
      "\n",
      "Train Epoch: [35/100 (00%)], cls_Loss: 0.119012, transfer_loss: 0.221155, total_Loss: 2.330563\n",
      "Train Epoch: [35/100 (30%)], cls_Loss: 0.148354, transfer_loss: 0.214279, total_Loss: 2.291142\n",
      "Train Epoch: [35/100 (60%)], cls_Loss: 0.120745, transfer_loss: 0.215121, total_Loss: 2.271955\n",
      "Train Epoch: [35/100 (90%)], cls_Loss: 0.123781, transfer_loss: 0.214371, total_Loss: 2.267494\n",
      "amazon --> webcam: max correct: 575, accuracy 72.33%\n",
      "\n",
      "Train Epoch: [36/100 (00%)], cls_Loss: 0.170513, transfer_loss: 0.224416, total_Loss: 2.414672\n",
      "Train Epoch: [36/100 (30%)], cls_Loss: 0.134855, transfer_loss: 0.218636, total_Loss: 2.321213\n",
      "Train Epoch: [36/100 (60%)], cls_Loss: 0.113366, transfer_loss: 0.216342, total_Loss: 2.276784\n",
      "Train Epoch: [36/100 (90%)], cls_Loss: 0.115082, transfer_loss: 0.215613, total_Loss: 2.271209\n",
      "amazon --> webcam: max correct: 588, accuracy 73.96%\n",
      "\n",
      "Train Epoch: [37/100 (00%)], cls_Loss: 0.024048, transfer_loss: 0.218794, total_Loss: 2.211991\n",
      "Train Epoch: [37/100 (30%)], cls_Loss: 0.092726, transfer_loss: 0.213786, total_Loss: 2.230585\n",
      "Train Epoch: [37/100 (60%)], cls_Loss: 0.104019, transfer_loss: 0.213272, total_Loss: 2.236739\n",
      "Train Epoch: [37/100 (90%)], cls_Loss: 0.087888, transfer_loss: 0.213952, total_Loss: 2.227413\n",
      "amazon --> webcam: max correct: 605, accuracy 76.10%\n",
      "\n",
      "Train Epoch: [38/100 (00%)], cls_Loss: 0.015780, transfer_loss: 0.208188, total_Loss: 2.097664\n",
      "Train Epoch: [38/100 (30%)], cls_Loss: 0.082988, transfer_loss: 0.217281, total_Loss: 2.255797\n",
      "Train Epoch: [38/100 (60%)], cls_Loss: 0.094479, transfer_loss: 0.217104, total_Loss: 2.265521\n",
      "Train Epoch: [38/100 (90%)], cls_Loss: 0.104527, transfer_loss: 0.216547, total_Loss: 2.269995\n",
      "amazon --> webcam: max correct: 603, accuracy 75.85%\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: [39/100 (00%)], cls_Loss: 0.019988, transfer_loss: 0.207038, total_Loss: 2.090372\n",
      "Train Epoch: [39/100 (30%)], cls_Loss: 0.054126, transfer_loss: 0.210623, total_Loss: 2.160356\n",
      "Train Epoch: [39/100 (60%)], cls_Loss: 0.054099, transfer_loss: 0.212965, total_Loss: 2.183749\n",
      "Train Epoch: [39/100 (90%)], cls_Loss: 0.070610, transfer_loss: 0.212999, total_Loss: 2.200602\n",
      "amazon --> webcam: max correct: 609, accuracy 76.60%\n",
      "\n",
      "Train Epoch: [40/100 (00%)], cls_Loss: 0.047268, transfer_loss: 0.207176, total_Loss: 2.119029\n",
      "Train Epoch: [40/100 (30%)], cls_Loss: 0.027260, transfer_loss: 0.210927, total_Loss: 2.136530\n",
      "Train Epoch: [40/100 (60%)], cls_Loss: 0.034407, transfer_loss: 0.212576, total_Loss: 2.160163\n",
      "Train Epoch: [40/100 (90%)], cls_Loss: 0.052142, transfer_loss: 0.213272, total_Loss: 2.184864\n",
      "amazon --> webcam: max correct: 590, accuracy 74.21%\n",
      "\n",
      "Train Epoch: [41/100 (00%)], cls_Loss: 0.021093, transfer_loss: 0.211607, total_Loss: 2.137164\n",
      "Train Epoch: [41/100 (30%)], cls_Loss: 0.076116, transfer_loss: 0.212694, total_Loss: 2.203058\n",
      "Train Epoch: [41/100 (60%)], cls_Loss: 0.068565, transfer_loss: 0.212245, total_Loss: 2.191019\n",
      "Train Epoch: [41/100 (90%)], cls_Loss: 0.074371, transfer_loss: 0.213012, total_Loss: 2.204487\n",
      "amazon --> webcam: max correct: 590, accuracy 74.21%\n",
      "\n",
      "Train Epoch: [42/100 (00%)], cls_Loss: 0.053791, transfer_loss: 0.209238, total_Loss: 2.146169\n",
      "Train Epoch: [42/100 (30%)], cls_Loss: 0.060087, transfer_loss: 0.212902, total_Loss: 2.189107\n",
      "Train Epoch: [42/100 (60%)], cls_Loss: 0.081840, transfer_loss: 0.212863, total_Loss: 2.210470\n",
      "Train Epoch: [42/100 (90%)], cls_Loss: 0.082329, transfer_loss: 0.212682, total_Loss: 2.209153\n",
      "amazon --> webcam: max correct: 572, accuracy 71.95%\n",
      "\n",
      "Train Epoch: [43/100 (00%)], cls_Loss: 0.062174, transfer_loss: 0.205655, total_Loss: 2.118726\n",
      "Train Epoch: [43/100 (30%)], cls_Loss: 0.078738, transfer_loss: 0.211601, total_Loss: 2.194750\n",
      "Train Epoch: [43/100 (60%)], cls_Loss: 0.074436, transfer_loss: 0.213546, total_Loss: 2.209898\n",
      "Train Epoch: [43/100 (90%)], cls_Loss: 0.069421, transfer_loss: 0.213565, total_Loss: 2.205076\n",
      "amazon --> webcam: max correct: 559, accuracy 70.31%\n",
      "\n",
      "Train Epoch: [44/100 (00%)], cls_Loss: 0.075771, transfer_loss: 0.220447, total_Loss: 2.280245\n",
      "Train Epoch: [44/100 (30%)], cls_Loss: 0.075175, transfer_loss: 0.217660, total_Loss: 2.251776\n",
      "Train Epoch: [44/100 (60%)], cls_Loss: 0.065440, transfer_loss: 0.215467, total_Loss: 2.220112\n",
      "Train Epoch: [44/100 (90%)], cls_Loss: 0.064826, transfer_loss: 0.215265, total_Loss: 2.217479\n",
      "amazon --> webcam: max correct: 570, accuracy 71.70%\n",
      "\n",
      "Train Epoch: [45/100 (00%)], cls_Loss: 0.028109, transfer_loss: 0.220318, total_Loss: 2.231292\n",
      "Train Epoch: [45/100 (30%)], cls_Loss: 0.024037, transfer_loss: 0.215863, total_Loss: 2.182663\n",
      "Train Epoch: [45/100 (60%)], cls_Loss: 0.035328, transfer_loss: 0.215925, total_Loss: 2.194577\n",
      "Train Epoch: [45/100 (90%)], cls_Loss: 0.042138, transfer_loss: 0.215982, total_Loss: 2.201957\n",
      "amazon --> webcam: max correct: 589, accuracy 74.09%\n",
      "\n",
      "Train Epoch: [46/100 (00%)], cls_Loss: 0.027418, transfer_loss: 0.207664, total_Loss: 2.104063\n",
      "Train Epoch: [46/100 (30%)], cls_Loss: 0.036636, transfer_loss: 0.211779, total_Loss: 2.154430\n",
      "Train Epoch: [46/100 (60%)], cls_Loss: 0.044971, transfer_loss: 0.213706, total_Loss: 2.182032\n",
      "Train Epoch: [46/100 (90%)], cls_Loss: 0.051791, transfer_loss: 0.214396, total_Loss: 2.195747\n",
      "amazon --> webcam: max correct: 563, accuracy 70.82%\n",
      "\n",
      "Train Epoch: [47/100 (00%)], cls_Loss: 0.130412, transfer_loss: 0.224061, total_Loss: 2.371025\n",
      "Train Epoch: [47/100 (30%)], cls_Loss: 0.068961, transfer_loss: 0.216998, total_Loss: 2.238943\n",
      "Train Epoch: [47/100 (60%)], cls_Loss: 0.069299, transfer_loss: 0.217548, total_Loss: 2.244781\n",
      "Train Epoch: [47/100 (90%)], cls_Loss: 0.058318, transfer_loss: 0.215814, total_Loss: 2.216457\n",
      "amazon --> webcam: max correct: 579, accuracy 72.83%\n",
      "\n",
      "Train Epoch: [48/100 (00%)], cls_Loss: 0.001539, transfer_loss: 0.221221, total_Loss: 2.213746\n",
      "Train Epoch: [48/100 (30%)], cls_Loss: 0.048508, transfer_loss: 0.215013, total_Loss: 2.198634\n",
      "Train Epoch: [48/100 (60%)], cls_Loss: 0.058459, transfer_loss: 0.214432, total_Loss: 2.202777\n",
      "Train Epoch: [48/100 (90%)], cls_Loss: 0.065735, transfer_loss: 0.214647, total_Loss: 2.212204\n",
      "amazon --> webcam: max correct: 581, accuracy 73.08%\n",
      "\n",
      "Train Epoch: [49/100 (00%)], cls_Loss: 0.487485, transfer_loss: 0.205632, total_Loss: 2.543802\n",
      "Train Epoch: [49/100 (30%)], cls_Loss: 0.124344, transfer_loss: 0.216196, total_Loss: 2.286303\n",
      "Train Epoch: [49/100 (60%)], cls_Loss: 0.086320, transfer_loss: 0.215105, total_Loss: 2.237369\n",
      "Train Epoch: [49/100 (90%)], cls_Loss: 0.066964, transfer_loss: 0.215392, total_Loss: 2.220885\n",
      "amazon --> webcam: max correct: 592, accuracy 74.47%\n",
      "\n",
      "Train Epoch: [50/100 (00%)], cls_Loss: 0.087736, transfer_loss: 0.207165, total_Loss: 2.159384\n",
      "Train Epoch: [50/100 (30%)], cls_Loss: 0.015638, transfer_loss: 0.213702, total_Loss: 2.152659\n",
      "Train Epoch: [50/100 (60%)], cls_Loss: 0.014985, transfer_loss: 0.212970, total_Loss: 2.144688\n",
      "Train Epoch: [50/100 (90%)], cls_Loss: 0.026717, transfer_loss: 0.214086, total_Loss: 2.167573\n",
      "amazon --> webcam: max correct: 595, accuracy 74.84%\n",
      "\n",
      "Train Epoch: [51/100 (00%)], cls_Loss: 0.006712, transfer_loss: 0.217671, total_Loss: 2.183426\n",
      "Train Epoch: [51/100 (30%)], cls_Loss: 0.108326, transfer_loss: 0.217507, total_Loss: 2.283394\n",
      "Train Epoch: [51/100 (60%)], cls_Loss: 0.089460, transfer_loss: 0.217312, total_Loss: 2.262580\n",
      "Train Epoch: [51/100 (90%)], cls_Loss: 0.066370, transfer_loss: 0.215577, total_Loss: 2.222140\n",
      "amazon --> webcam: max correct: 556, accuracy 69.94%\n",
      "\n",
      "Train Epoch: [52/100 (00%)], cls_Loss: 0.060516, transfer_loss: 0.220755, total_Loss: 2.268066\n",
      "Train Epoch: [52/100 (30%)], cls_Loss: 0.037422, transfer_loss: 0.214291, total_Loss: 2.180333\n",
      "Train Epoch: [52/100 (60%)], cls_Loss: 0.023784, transfer_loss: 0.214778, total_Loss: 2.171564\n",
      "Train Epoch: [52/100 (90%)], cls_Loss: 0.059489, transfer_loss: 0.213650, total_Loss: 2.195989\n",
      "amazon --> webcam: max correct: 559, accuracy 70.31%\n",
      "\n",
      "Train Epoch: [53/100 (00%)], cls_Loss: 0.001164, transfer_loss: 0.207004, total_Loss: 2.071200\n",
      "Train Epoch: [53/100 (30%)], cls_Loss: 0.085728, transfer_loss: 0.215248, total_Loss: 2.238208\n",
      "Train Epoch: [53/100 (60%)], cls_Loss: 0.057180, transfer_loss: 0.213810, total_Loss: 2.195277\n",
      "Train Epoch: [53/100 (90%)], cls_Loss: 0.080368, transfer_loss: 0.214086, total_Loss: 2.221226\n",
      "amazon --> webcam: max correct: 547, accuracy 68.81%\n",
      "\n",
      "Train Epoch: [54/100 (00%)], cls_Loss: 0.014471, transfer_loss: 0.231551, total_Loss: 2.329984\n",
      "Train Epoch: [54/100 (30%)], cls_Loss: 0.118439, transfer_loss: 0.217371, total_Loss: 2.292151\n",
      "Train Epoch: [54/100 (60%)], cls_Loss: 0.122298, transfer_loss: 0.213829, total_Loss: 2.260590\n",
      "Train Epoch: [54/100 (90%)], cls_Loss: 0.099474, transfer_loss: 0.213808, total_Loss: 2.237554\n",
      "amazon --> webcam: max correct: 546, accuracy 68.68%\n",
      "\n",
      "Train Epoch: [55/100 (00%)], cls_Loss: 0.008275, transfer_loss: 0.213441, total_Loss: 2.142683\n",
      "Train Epoch: [55/100 (30%)], cls_Loss: 0.052027, transfer_loss: 0.214208, total_Loss: 2.194111\n",
      "Train Epoch: [55/100 (60%)], cls_Loss: 0.034295, transfer_loss: 0.213715, total_Loss: 2.171441\n",
      "Train Epoch: [55/100 (90%)], cls_Loss: 0.044886, transfer_loss: 0.213867, total_Loss: 2.183556\n",
      "amazon --> webcam: max correct: 568, accuracy 71.45%\n",
      "\n",
      "Train Epoch: [56/100 (00%)], cls_Loss: 0.000388, transfer_loss: 0.226239, total_Loss: 2.262778\n",
      "Train Epoch: [56/100 (30%)], cls_Loss: 0.045406, transfer_loss: 0.218327, total_Loss: 2.228680\n",
      "Train Epoch: [56/100 (60%)], cls_Loss: 0.047113, transfer_loss: 0.216302, total_Loss: 2.210134\n",
      "Train Epoch: [56/100 (90%)], cls_Loss: 0.053971, transfer_loss: 0.215019, total_Loss: 2.204159\n",
      "amazon --> webcam: max correct: 577, accuracy 72.58%\n",
      "\n",
      "Train Epoch: [57/100 (00%)], cls_Loss: 0.005191, transfer_loss: 0.208186, total_Loss: 2.087051\n",
      "Train Epoch: [57/100 (30%)], cls_Loss: 0.028320, transfer_loss: 0.211728, total_Loss: 2.145602\n",
      "Train Epoch: [57/100 (60%)], cls_Loss: 0.058562, transfer_loss: 0.212812, total_Loss: 2.186686\n",
      "Train Epoch: [57/100 (90%)], cls_Loss: 0.053141, transfer_loss: 0.213162, total_Loss: 2.184763\n",
      "amazon --> webcam: max correct: 561, accuracy 70.57%\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: [58/100 (00%)], cls_Loss: 0.070110, transfer_loss: 0.227588, total_Loss: 2.345991\n",
      "Train Epoch: [58/100 (30%)], cls_Loss: 0.034633, transfer_loss: 0.216895, total_Loss: 2.203581\n",
      "Train Epoch: [58/100 (60%)], cls_Loss: 0.036369, transfer_loss: 0.215090, total_Loss: 2.187272\n",
      "Train Epoch: [58/100 (90%)], cls_Loss: 0.049014, transfer_loss: 0.215328, total_Loss: 2.202297\n",
      "amazon --> webcam: max correct: 568, accuracy 71.45%\n",
      "\n",
      "Train Epoch: [59/100 (00%)], cls_Loss: 0.071605, transfer_loss: 0.205809, total_Loss: 2.129691\n",
      "Train Epoch: [59/100 (30%)], cls_Loss: 0.030140, transfer_loss: 0.213742, total_Loss: 2.167563\n",
      "Train Epoch: [59/100 (60%)], cls_Loss: 0.029753, transfer_loss: 0.215004, total_Loss: 2.179792\n",
      "Train Epoch: [59/100 (90%)], cls_Loss: 0.035903, transfer_loss: 0.214145, total_Loss: 2.177350\n",
      "amazon --> webcam: max correct: 563, accuracy 70.82%\n",
      "\n",
      "Train Epoch: [60/100 (00%)], cls_Loss: 0.011070, transfer_loss: 0.212952, total_Loss: 2.140586\n",
      "Train Epoch: [60/100 (30%)], cls_Loss: 0.044138, transfer_loss: 0.216145, total_Loss: 2.205592\n",
      "Train Epoch: [60/100 (60%)], cls_Loss: 0.046045, transfer_loss: 0.214569, total_Loss: 2.191737\n",
      "Train Epoch: [60/100 (90%)], cls_Loss: 0.037415, transfer_loss: 0.215779, total_Loss: 2.195204\n",
      "amazon --> webcam: max correct: 565, accuracy 71.07%\n",
      "\n",
      "Train Epoch: [61/100 (00%)], cls_Loss: 0.001933, transfer_loss: 0.217678, total_Loss: 2.178713\n",
      "Train Epoch: [61/100 (30%)], cls_Loss: 0.037410, transfer_loss: 0.215554, total_Loss: 2.192949\n",
      "Train Epoch: [61/100 (60%)], cls_Loss: 0.031688, transfer_loss: 0.214553, total_Loss: 2.177218\n",
      "Train Epoch: [61/100 (90%)], cls_Loss: 0.041715, transfer_loss: 0.214168, total_Loss: 2.183393\n",
      "amazon --> webcam: max correct: 589, accuracy 74.09%\n",
      "\n",
      "Train Epoch: [62/100 (00%)], cls_Loss: 0.003757, transfer_loss: 0.234973, total_Loss: 2.353485\n",
      "Train Epoch: [62/100 (30%)], cls_Loss: 0.030889, transfer_loss: 0.217771, total_Loss: 2.208604\n",
      "Train Epoch: [62/100 (60%)], cls_Loss: 0.024843, transfer_loss: 0.217586, total_Loss: 2.200702\n",
      "Train Epoch: [62/100 (90%)], cls_Loss: 0.018794, transfer_loss: 0.216747, total_Loss: 2.186263\n",
      "amazon --> webcam: max correct: 592, accuracy 74.47%\n",
      "\n",
      "Train Epoch: [63/100 (00%)], cls_Loss: 0.004771, transfer_loss: 0.214707, total_Loss: 2.151846\n",
      "Train Epoch: [63/100 (30%)], cls_Loss: 0.058439, transfer_loss: 0.214730, total_Loss: 2.205735\n",
      "Train Epoch: [63/100 (60%)], cls_Loss: 0.049010, transfer_loss: 0.214312, total_Loss: 2.192129\n",
      "Train Epoch: [63/100 (90%)], cls_Loss: 0.053366, transfer_loss: 0.215511, total_Loss: 2.208481\n",
      "amazon --> webcam: max correct: 538, accuracy 67.67%\n",
      "\n",
      "Train Epoch: [64/100 (00%)], cls_Loss: 0.009033, transfer_loss: 0.205295, total_Loss: 2.061987\n",
      "Train Epoch: [64/100 (30%)], cls_Loss: 0.065395, transfer_loss: 0.214629, total_Loss: 2.211680\n",
      "Train Epoch: [64/100 (60%)], cls_Loss: 0.039098, transfer_loss: 0.214697, total_Loss: 2.186073\n",
      "Train Epoch: [64/100 (90%)], cls_Loss: 0.032575, transfer_loss: 0.213236, total_Loss: 2.164935\n",
      "amazon --> webcam: max correct: 571, accuracy 71.82%\n",
      "\n",
      "Train Epoch: [65/100 (00%)], cls_Loss: 0.001052, transfer_loss: 0.211507, total_Loss: 2.116120\n",
      "Train Epoch: [65/100 (30%)], cls_Loss: 0.036205, transfer_loss: 0.216592, total_Loss: 2.202124\n",
      "Train Epoch: [65/100 (60%)], cls_Loss: 0.027481, transfer_loss: 0.216050, total_Loss: 2.187981\n",
      "Train Epoch: [65/100 (90%)], cls_Loss: 0.031348, transfer_loss: 0.215694, total_Loss: 2.188284\n",
      "amazon --> webcam: max correct: 563, accuracy 70.82%\n",
      "\n",
      "Train Epoch: [66/100 (00%)], cls_Loss: 0.003037, transfer_loss: 0.217422, total_Loss: 2.177260\n",
      "Train Epoch: [66/100 (30%)], cls_Loss: 0.039307, transfer_loss: 0.213629, total_Loss: 2.175596\n",
      "Train Epoch: [66/100 (60%)], cls_Loss: 0.049504, transfer_loss: 0.214183, total_Loss: 2.191330\n",
      "Train Epoch: [66/100 (90%)], cls_Loss: 0.038779, transfer_loss: 0.214998, total_Loss: 2.188762\n",
      "amazon --> webcam: max correct: 580, accuracy 72.96%\n",
      "\n",
      "Train Epoch: [67/100 (00%)], cls_Loss: 0.000417, transfer_loss: 0.208578, total_Loss: 2.086200\n",
      "Train Epoch: [67/100 (30%)], cls_Loss: 0.036198, transfer_loss: 0.215163, total_Loss: 2.187825\n",
      "Train Epoch: [67/100 (60%)], cls_Loss: 0.060808, transfer_loss: 0.213840, total_Loss: 2.199209\n",
      "Train Epoch: [67/100 (90%)], cls_Loss: 0.046416, transfer_loss: 0.213539, total_Loss: 2.181804\n",
      "amazon --> webcam: max correct: 574, accuracy 72.20%\n",
      "\n",
      "Train Epoch: [68/100 (00%)], cls_Loss: 0.080977, transfer_loss: 0.220798, total_Loss: 2.288953\n",
      "Train Epoch: [68/100 (30%)], cls_Loss: 0.069040, transfer_loss: 0.216421, total_Loss: 2.233247\n",
      "Train Epoch: [68/100 (60%)], cls_Loss: 0.046385, transfer_loss: 0.215320, total_Loss: 2.199589\n",
      "Train Epoch: [68/100 (90%)], cls_Loss: 0.057986, transfer_loss: 0.215487, total_Loss: 2.212857\n",
      "amazon --> webcam: max correct: 568, accuracy 71.45%\n",
      "\n",
      "Train Epoch: [69/100 (00%)], cls_Loss: 0.001104, transfer_loss: 0.212549, total_Loss: 2.126596\n",
      "Train Epoch: [69/100 (30%)], cls_Loss: 0.025713, transfer_loss: 0.215909, total_Loss: 2.184803\n",
      "Train Epoch: [69/100 (60%)], cls_Loss: 0.046995, transfer_loss: 0.215999, total_Loss: 2.206988\n",
      "Train Epoch: [69/100 (90%)], cls_Loss: 0.047988, transfer_loss: 0.214537, total_Loss: 2.193359\n",
      "amazon --> webcam: max correct: 561, accuracy 70.57%\n",
      "\n",
      "Train Epoch: [70/100 (00%)], cls_Loss: 0.056292, transfer_loss: 0.213704, total_Loss: 2.193332\n",
      "Train Epoch: [70/100 (30%)], cls_Loss: 0.092513, transfer_loss: 0.213959, total_Loss: 2.232102\n",
      "Train Epoch: [70/100 (60%)], cls_Loss: 0.070162, transfer_loss: 0.214205, total_Loss: 2.212208\n",
      "Train Epoch: [70/100 (90%)], cls_Loss: 0.057042, transfer_loss: 0.214212, total_Loss: 2.199165\n",
      "amazon --> webcam: max correct: 565, accuracy 71.07%\n",
      "\n",
      "Train Epoch: [71/100 (00%)], cls_Loss: 0.001753, transfer_loss: 0.216004, total_Loss: 2.161797\n",
      "Train Epoch: [71/100 (30%)], cls_Loss: 0.088809, transfer_loss: 0.213143, total_Loss: 2.220234\n",
      "Train Epoch: [71/100 (60%)], cls_Loss: 0.059984, transfer_loss: 0.213372, total_Loss: 2.193704\n",
      "Train Epoch: [71/100 (90%)], cls_Loss: 0.064324, transfer_loss: 0.214354, total_Loss: 2.207867\n",
      "amazon --> webcam: max correct: 552, accuracy 69.43%\n",
      "\n",
      "Train Epoch: [72/100 (00%)], cls_Loss: 0.007901, transfer_loss: 0.218181, total_Loss: 2.189713\n",
      "Train Epoch: [72/100 (30%)], cls_Loss: 0.032463, transfer_loss: 0.215138, total_Loss: 2.183841\n",
      "Train Epoch: [72/100 (60%)], cls_Loss: 0.043004, transfer_loss: 0.214579, total_Loss: 2.188799\n",
      "Train Epoch: [72/100 (90%)], cls_Loss: 0.041599, transfer_loss: 0.214881, total_Loss: 2.190408\n",
      "amazon --> webcam: max correct: 571, accuracy 71.82%\n",
      "\n",
      "Train Epoch: [73/100 (00%)], cls_Loss: 0.004940, transfer_loss: 0.224923, total_Loss: 2.254166\n",
      "Train Epoch: [73/100 (30%)], cls_Loss: 0.028838, transfer_loss: 0.214375, total_Loss: 2.172587\n",
      "Train Epoch: [73/100 (60%)], cls_Loss: 0.032643, transfer_loss: 0.214061, total_Loss: 2.173255\n",
      "Train Epoch: [73/100 (90%)], cls_Loss: 0.025798, transfer_loss: 0.213918, total_Loss: 2.164981\n",
      "amazon --> webcam: max correct: 563, accuracy 70.82%\n",
      "\n",
      "Train Epoch: [74/100 (00%)], cls_Loss: 0.141613, transfer_loss: 0.219639, total_Loss: 2.338002\n",
      "Train Epoch: [74/100 (30%)], cls_Loss: 0.027862, transfer_loss: 0.214955, total_Loss: 2.177414\n",
      "Train Epoch: [74/100 (60%)], cls_Loss: 0.041889, transfer_loss: 0.213698, total_Loss: 2.178870\n",
      "Train Epoch: [74/100 (90%)], cls_Loss: 0.040568, transfer_loss: 0.213641, total_Loss: 2.176980\n",
      "amazon --> webcam: max correct: 570, accuracy 71.70%\n",
      "\n",
      "Train Epoch: [75/100 (00%)], cls_Loss: 0.010588, transfer_loss: 0.215836, total_Loss: 2.168952\n",
      "Train Epoch: [75/100 (30%)], cls_Loss: 0.021751, transfer_loss: 0.213651, total_Loss: 2.158258\n",
      "Train Epoch: [75/100 (60%)], cls_Loss: 0.029178, transfer_loss: 0.213380, total_Loss: 2.162980\n",
      "Train Epoch: [75/100 (90%)], cls_Loss: 0.027846, transfer_loss: 0.214129, total_Loss: 2.169137\n",
      "amazon --> webcam: max correct: 568, accuracy 71.45%\n",
      "\n",
      "Train Epoch: [76/100 (00%)], cls_Loss: 0.000111, transfer_loss: 0.204341, total_Loss: 2.043517\n",
      "Train Epoch: [76/100 (30%)], cls_Loss: 0.029448, transfer_loss: 0.213928, total_Loss: 2.168733\n",
      "Train Epoch: [76/100 (60%)], cls_Loss: 0.030341, transfer_loss: 0.213743, total_Loss: 2.167767\n",
      "Train Epoch: [76/100 (90%)], cls_Loss: 0.037636, transfer_loss: 0.214463, total_Loss: 2.182266\n",
      "amazon --> webcam: max correct: 572, accuracy 71.95%\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: [77/100 (00%)], cls_Loss: 0.000397, transfer_loss: 0.213452, total_Loss: 2.134918\n",
      "Train Epoch: [77/100 (30%)], cls_Loss: 0.035443, transfer_loss: 0.212858, total_Loss: 2.164020\n",
      "Train Epoch: [77/100 (60%)], cls_Loss: 0.034148, transfer_loss: 0.213603, total_Loss: 2.170181\n",
      "Train Epoch: [77/100 (90%)], cls_Loss: 0.036014, transfer_loss: 0.212507, total_Loss: 2.161084\n",
      "amazon --> webcam: max correct: 567, accuracy 71.32%\n",
      "\n",
      "Train Epoch: [78/100 (00%)], cls_Loss: 0.029592, transfer_loss: 0.204070, total_Loss: 2.070288\n",
      "Train Epoch: [78/100 (30%)], cls_Loss: 0.029422, transfer_loss: 0.211534, total_Loss: 2.144761\n",
      "Train Epoch: [78/100 (60%)], cls_Loss: 0.018290, transfer_loss: 0.212289, total_Loss: 2.141180\n",
      "Train Epoch: [78/100 (90%)], cls_Loss: 0.035717, transfer_loss: 0.211982, total_Loss: 2.155538\n",
      "amazon --> webcam: max correct: 532, accuracy 66.92%\n",
      "\n",
      "Train Epoch: [79/100 (00%)], cls_Loss: 0.043439, transfer_loss: 0.210397, total_Loss: 2.147404\n",
      "Train Epoch: [79/100 (30%)], cls_Loss: 0.019612, transfer_loss: 0.211505, total_Loss: 2.134666\n",
      "Train Epoch: [79/100 (60%)], cls_Loss: 0.026831, transfer_loss: 0.213420, total_Loss: 2.161030\n",
      "Train Epoch: [79/100 (90%)], cls_Loss: 0.020678, transfer_loss: 0.213793, total_Loss: 2.158603\n",
      "amazon --> webcam: max correct: 579, accuracy 72.83%\n",
      "\n",
      "Train Epoch: [80/100 (00%)], cls_Loss: 0.002051, transfer_loss: 0.210560, total_Loss: 2.107650\n",
      "Train Epoch: [80/100 (30%)], cls_Loss: 0.010474, transfer_loss: 0.214052, total_Loss: 2.150993\n",
      "Train Epoch: [80/100 (60%)], cls_Loss: 0.017023, transfer_loss: 0.213381, total_Loss: 2.150832\n",
      "Train Epoch: [80/100 (90%)], cls_Loss: 0.026592, transfer_loss: 0.213692, total_Loss: 2.163508\n",
      "amazon --> webcam: max correct: 549, accuracy 69.06%\n",
      "\n",
      "Train Epoch: [81/100 (00%)], cls_Loss: 0.000526, transfer_loss: 0.207580, total_Loss: 2.076325\n",
      "Train Epoch: [81/100 (30%)], cls_Loss: 0.031322, transfer_loss: 0.211104, total_Loss: 2.142363\n",
      "Train Epoch: [81/100 (60%)], cls_Loss: 0.055762, transfer_loss: 0.212256, total_Loss: 2.178324\n",
      "Train Epoch: [81/100 (90%)], cls_Loss: 0.044935, transfer_loss: 0.213520, total_Loss: 2.180135\n",
      "amazon --> webcam: max correct: 568, accuracy 71.45%\n",
      "\n",
      "Train Epoch: [82/100 (00%)], cls_Loss: 0.002705, transfer_loss: 0.214743, total_Loss: 2.150140\n",
      "Train Epoch: [82/100 (30%)], cls_Loss: 0.026021, transfer_loss: 0.214454, total_Loss: 2.170563\n",
      "Train Epoch: [82/100 (60%)], cls_Loss: 0.021779, transfer_loss: 0.213958, total_Loss: 2.161356\n",
      "Train Epoch: [82/100 (90%)], cls_Loss: 0.046738, transfer_loss: 0.214124, total_Loss: 2.187976\n",
      "amazon --> webcam: max correct: 583, accuracy 73.33%\n",
      "\n",
      "Train Epoch: [83/100 (00%)], cls_Loss: 0.069693, transfer_loss: 0.211511, total_Loss: 2.184808\n",
      "Train Epoch: [83/100 (30%)], cls_Loss: 0.056344, transfer_loss: 0.212917, total_Loss: 2.185517\n",
      "Train Epoch: [83/100 (60%)], cls_Loss: 0.041016, transfer_loss: 0.215486, total_Loss: 2.195877\n",
      "Train Epoch: [83/100 (90%)], cls_Loss: 0.032783, transfer_loss: 0.215132, total_Loss: 2.184100\n",
      "amazon --> webcam: max correct: 564, accuracy 70.94%\n",
      "\n",
      "Train Epoch: [84/100 (00%)], cls_Loss: 0.000839, transfer_loss: 0.207543, total_Loss: 2.076268\n",
      "Train Epoch: [84/100 (30%)], cls_Loss: 0.049876, transfer_loss: 0.211308, total_Loss: 2.162951\n",
      "Train Epoch: [84/100 (60%)], cls_Loss: 0.030322, transfer_loss: 0.212283, total_Loss: 2.153156\n",
      "Train Epoch: [84/100 (90%)], cls_Loss: 0.028067, transfer_loss: 0.214221, total_Loss: 2.170278\n",
      "amazon --> webcam: max correct: 560, accuracy 70.44%\n",
      "\n",
      "Train Epoch: [85/100 (00%)], cls_Loss: 0.045534, transfer_loss: 0.216132, total_Loss: 2.206850\n",
      "Train Epoch: [85/100 (30%)], cls_Loss: 0.069113, transfer_loss: 0.213873, total_Loss: 2.207842\n",
      "Train Epoch: [85/100 (60%)], cls_Loss: 0.046846, transfer_loss: 0.215157, total_Loss: 2.198419\n",
      "Train Epoch: [85/100 (90%)], cls_Loss: 0.033981, transfer_loss: 0.214399, total_Loss: 2.177966\n",
      "amazon --> webcam: max correct: 559, accuracy 70.31%\n",
      "\n",
      "Train Epoch: [86/100 (00%)], cls_Loss: 0.032428, transfer_loss: 0.221206, total_Loss: 2.244491\n",
      "Train Epoch: [86/100 (30%)], cls_Loss: 0.028623, transfer_loss: 0.214957, total_Loss: 2.178194\n",
      "Train Epoch: [86/100 (60%)], cls_Loss: 0.021020, transfer_loss: 0.214806, total_Loss: 2.169081\n",
      "Train Epoch: [86/100 (90%)], cls_Loss: 0.023476, transfer_loss: 0.214405, total_Loss: 2.167527\n",
      "amazon --> webcam: max correct: 563, accuracy 70.82%\n",
      "\n",
      "Train Epoch: [87/100 (00%)], cls_Loss: 0.104077, transfer_loss: 0.220767, total_Loss: 2.311749\n",
      "Train Epoch: [87/100 (30%)], cls_Loss: 0.063831, transfer_loss: 0.217689, total_Loss: 2.240720\n",
      "Train Epoch: [87/100 (60%)], cls_Loss: 0.040063, transfer_loss: 0.215480, total_Loss: 2.194868\n",
      "Train Epoch: [87/100 (90%)], cls_Loss: 0.030974, transfer_loss: 0.215069, total_Loss: 2.181660\n",
      "amazon --> webcam: max correct: 596, accuracy 74.97%\n",
      "\n",
      "Train Epoch: [88/100 (00%)], cls_Loss: 0.000125, transfer_loss: 0.211783, total_Loss: 2.117959\n",
      "Train Epoch: [88/100 (30%)], cls_Loss: 0.015799, transfer_loss: 0.211232, total_Loss: 2.128115\n",
      "Train Epoch: [88/100 (60%)], cls_Loss: 0.010965, transfer_loss: 0.211765, total_Loss: 2.128618\n",
      "Train Epoch: [88/100 (90%)], cls_Loss: 0.009685, transfer_loss: 0.212901, total_Loss: 2.138691\n",
      "amazon --> webcam: max correct: 593, accuracy 74.59%\n",
      "\n",
      "Train Epoch: [89/100 (00%)], cls_Loss: 0.176028, transfer_loss: 0.223086, total_Loss: 2.406893\n",
      "Train Epoch: [89/100 (30%)], cls_Loss: 0.032579, transfer_loss: 0.215998, total_Loss: 2.192556\n",
      "Train Epoch: [89/100 (60%)], cls_Loss: 0.043219, transfer_loss: 0.215375, total_Loss: 2.196965\n",
      "Train Epoch: [89/100 (90%)], cls_Loss: 0.032357, transfer_loss: 0.214517, total_Loss: 2.177526\n",
      "amazon --> webcam: max correct: 587, accuracy 73.84%\n",
      "\n",
      "Train Epoch: [90/100 (00%)], cls_Loss: 0.023941, transfer_loss: 0.207933, total_Loss: 2.103270\n",
      "Train Epoch: [90/100 (30%)], cls_Loss: 0.008231, transfer_loss: 0.215610, total_Loss: 2.164328\n",
      "Train Epoch: [90/100 (60%)], cls_Loss: 0.010961, transfer_loss: 0.214139, total_Loss: 2.152348\n",
      "Train Epoch: [90/100 (90%)], cls_Loss: 0.010720, transfer_loss: 0.214861, total_Loss: 2.159329\n",
      "amazon --> webcam: max correct: 564, accuracy 70.94%\n",
      "\n",
      "Train Epoch: [91/100 (00%)], cls_Loss: 0.001062, transfer_loss: 0.207296, total_Loss: 2.074027\n",
      "Train Epoch: [91/100 (30%)], cls_Loss: 0.022831, transfer_loss: 0.214065, total_Loss: 2.163482\n",
      "Train Epoch: [91/100 (60%)], cls_Loss: 0.022795, transfer_loss: 0.213286, total_Loss: 2.155657\n",
      "Train Epoch: [91/100 (90%)], cls_Loss: 0.020269, transfer_loss: 0.213598, total_Loss: 2.156248\n",
      "amazon --> webcam: max correct: 574, accuracy 72.20%\n",
      "\n",
      "Train Epoch: [92/100 (00%)], cls_Loss: 0.046474, transfer_loss: 0.215883, total_Loss: 2.205300\n",
      "Train Epoch: [92/100 (30%)], cls_Loss: 0.024003, transfer_loss: 0.211811, total_Loss: 2.142115\n",
      "Train Epoch: [92/100 (60%)], cls_Loss: 0.021379, transfer_loss: 0.213337, total_Loss: 2.154747\n",
      "Train Epoch: [92/100 (90%)], cls_Loss: 0.022581, transfer_loss: 0.212556, total_Loss: 2.148144\n",
      "amazon --> webcam: max correct: 575, accuracy 72.33%\n",
      "\n",
      "Train Epoch: [93/100 (00%)], cls_Loss: 0.013630, transfer_loss: 0.218896, total_Loss: 2.202594\n",
      "Train Epoch: [93/100 (30%)], cls_Loss: 0.063545, transfer_loss: 0.215681, total_Loss: 2.220360\n",
      "Train Epoch: [93/100 (60%)], cls_Loss: 0.043055, transfer_loss: 0.215923, total_Loss: 2.202289\n",
      "Train Epoch: [93/100 (90%)], cls_Loss: 0.045127, transfer_loss: 0.215824, total_Loss: 2.203363\n",
      "amazon --> webcam: max correct: 575, accuracy 72.33%\n",
      "\n",
      "Train Epoch: [94/100 (00%)], cls_Loss: 0.089006, transfer_loss: 0.209409, total_Loss: 2.183091\n",
      "Train Epoch: [94/100 (30%)], cls_Loss: 0.059298, transfer_loss: 0.213119, total_Loss: 2.190490\n",
      "Train Epoch: [94/100 (60%)], cls_Loss: 0.046876, transfer_loss: 0.213121, total_Loss: 2.178082\n",
      "Train Epoch: [94/100 (90%)], cls_Loss: 0.048521, transfer_loss: 0.212840, total_Loss: 2.176925\n",
      "amazon --> webcam: max correct: 573, accuracy 72.08%\n",
      "\n",
      "Train Epoch: [95/100 (00%)], cls_Loss: 0.005418, transfer_loss: 0.215810, total_Loss: 2.163515\n",
      "Train Epoch: [95/100 (30%)], cls_Loss: 0.015832, transfer_loss: 0.212314, total_Loss: 2.138969\n",
      "Train Epoch: [95/100 (60%)], cls_Loss: 0.016845, transfer_loss: 0.212221, total_Loss: 2.139060\n",
      "Train Epoch: [95/100 (90%)], cls_Loss: 0.035235, transfer_loss: 0.214030, total_Loss: 2.175533\n",
      "amazon --> webcam: max correct: 561, accuracy 70.57%\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: [96/100 (00%)], cls_Loss: 0.002461, transfer_loss: 0.211558, total_Loss: 2.118037\n",
      "Train Epoch: [96/100 (30%)], cls_Loss: 0.018805, transfer_loss: 0.214414, total_Loss: 2.162947\n",
      "Train Epoch: [96/100 (60%)], cls_Loss: 0.025988, transfer_loss: 0.215871, total_Loss: 2.184701\n",
      "Train Epoch: [96/100 (90%)], cls_Loss: 0.030735, transfer_loss: 0.215432, total_Loss: 2.185057\n",
      "amazon --> webcam: max correct: 569, accuracy 71.57%\n",
      "\n",
      "Train Epoch: [97/100 (00%)], cls_Loss: 0.006343, transfer_loss: 0.213133, total_Loss: 2.137676\n",
      "Train Epoch: [97/100 (30%)], cls_Loss: 0.061539, transfer_loss: 0.212608, total_Loss: 2.187621\n",
      "Train Epoch: [97/100 (60%)], cls_Loss: 0.048685, transfer_loss: 0.213476, total_Loss: 2.183442\n",
      "Train Epoch: [97/100 (90%)], cls_Loss: 0.038488, transfer_loss: 0.213383, total_Loss: 2.172313\n",
      "amazon --> webcam: max correct: 571, accuracy 71.82%\n",
      "\n",
      "Train Epoch: [98/100 (00%)], cls_Loss: 0.007120, transfer_loss: 0.214763, total_Loss: 2.154753\n",
      "Train Epoch: [98/100 (30%)], cls_Loss: 0.021872, transfer_loss: 0.215474, total_Loss: 2.176615\n",
      "Train Epoch: [98/100 (60%)], cls_Loss: 0.023694, transfer_loss: 0.215857, total_Loss: 2.182266\n",
      "Train Epoch: [98/100 (90%)], cls_Loss: 0.027439, transfer_loss: 0.216113, total_Loss: 2.188567\n",
      "amazon --> webcam: max correct: 576, accuracy 72.45%\n",
      "\n",
      "Train Epoch: [99/100 (00%)], cls_Loss: 0.002602, transfer_loss: 0.212816, total_Loss: 2.130766\n",
      "Train Epoch: [99/100 (30%)], cls_Loss: 0.010419, transfer_loss: 0.216248, total_Loss: 2.172896\n",
      "Train Epoch: [99/100 (60%)], cls_Loss: 0.027320, transfer_loss: 0.217146, total_Loss: 2.198782\n",
      "Train Epoch: [99/100 (90%)], cls_Loss: 0.027629, transfer_loss: 0.216449, total_Loss: 2.192114\n",
      "amazon --> webcam: max correct: 582, accuracy 73.21%\n",
      "\n",
      "Train Epoch: [100/100 (00%)], cls_Loss: 0.002904, transfer_loss: 0.207407, total_Loss: 2.076969\n",
      "Train Epoch: [100/100 (30%)], cls_Loss: 0.012950, transfer_loss: 0.212880, total_Loss: 2.141749\n",
      "Train Epoch: [100/100 (60%)], cls_Loss: 0.013185, transfer_loss: 0.213979, total_Loss: 2.152975\n",
      "Train Epoch: [100/100 (90%)], cls_Loss: 0.012504, transfer_loss: 0.213911, total_Loss: 2.151612\n",
      "amazon --> webcam: max correct: 588, accuracy 73.96%\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model = Transfer_Net(\n",
    "    CFG['n_class'], transfer_loss='mmd', base_net='resnet50').to(DEVICE)\n",
    "optimizer = torch.optim.SGD([\n",
    "    {'params': model.base_network.parameters()},\n",
    "    {'params': model.bottleneck_layer.parameters(), 'lr': 10 * CFG['lr']},\n",
    "    {'params': model.classifier_layer.parameters(), 'lr': 10 * CFG['lr']},\n",
    "], lr=CFG['lr'], momentum=CFG['momentum'], weight_decay=CFG['l2_decay'])\n",
    "\n",
    "train(source_loader, target_train_loader,\n",
    "      target_test_loader, model, optimizer, CFG)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[3.3018638292948403, 0.21489320740555273, 5.4507958961255625], [2.4047134572809394, 0.2144298372846661, 4.549011859026822], [1.3790370280092412, 0.2150639367826057, 3.5296764012539024], [1.0321817072955044, 0.21418277061346805, 3.174009417042588], [0.971176901550004, 0.2143961407921531, 3.1151383139870386], [0.7628376953529589, 0.21502716613538336, 2.91310935309439], [0.6599853612256773, 0.2139359459732518, 2.7993448286345513], [0.5769550678404894, 0.21494379549315482, 2.726393034963897], [0.46690843999385834, 0.2133214690468528, 2.600123138138742], [0.5311023563598142, 0.21573133179635712, 2.688415693514275]]\n",
      "[[tensor(27, device='cuda:0'), tensor(221, device='cuda:0'), 795], [tensor(46, device='cuda:0'), tensor(367, device='cuda:0'), 795], [tensor(57, device='cuda:0'), tensor(454, device='cuda:0'), 795], [tensor(55, device='cuda:0'), tensor(445, device='cuda:0'), 795], [tensor(70, device='cuda:0'), tensor(563, device='cuda:0'), 795], [tensor(68, device='cuda:0'), tensor(545, device='cuda:0'), 795], [tensor(70, device='cuda:0'), tensor(557, device='cuda:0'), 795], [tensor(71, device='cuda:0'), tensor(570, device='cuda:0'), 795], [tensor(73, device='cuda:0'), tensor(587, device='cuda:0'), 795], [tensor(73, device='cuda:0'), tensor(585, device='cuda:0'), 795]]\n"
     ]
    }
   ],
   "source": [
    "print(log[:10])\n",
    "print(acc[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 648x216 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# Fixing random state for reproducibility\n",
    "np.random.seed(19680801)\n",
    "\n",
    "\n",
    "# create some data to use for the plot\n",
    "\n",
    "t = np.arange(0, 100)\n",
    "#fig, axis = plt.subplots(1, 2, figsize=(9, 3), sharey=True)\n",
    "fig, axis = plt.subplots(nrows=1, ncols=2,  figsize=(9, 3),sharex=True)\n",
    "\n",
    "cls_loss_ = [a[0] for a in log]\n",
    "trans_loss_ = [a[1] for a in log]\n",
    "total_loss_ = [a[2] for a in log]\n",
    "#print(src_loss_[:10])\n",
    "# the main axes is subplot(111) by default\n",
    "axis[0].plot(t, cls_loss_,'g',label='cls_loss' )\n",
    "axis[0].plot(t, trans_loss_, 'b',label='trans_loss')\n",
    "axis[0].plot(t, total_loss_, 'r',label='total_loss')\n",
    "#axis[0].set_title('losses')\n",
    "axis[0].set_xlabel('epoch (s)')\n",
    "axis[0].set_ylabel('loss(es)')\n",
    "\n",
    "#src_acc_ = [a[1].cpu().numpy() for a in acc_hist[::3]]\n",
    "#val_acc_ = [a[1].cpu().numpy() for a in acc_hist[1::3]]\n",
    "test_acc_ = [float(a[0].cpu().numpy()) for a in acc]\n",
    "#print(src_acc_[:10])\n",
    "# the main axes is subplot(111) by default\n",
    "#axis[1].plot(t, src_acc_,'g+' ,label='acc_train')\n",
    "#axis[1].plot(t, val_acc_, 'b+',label='acc_val')\n",
    "axis[1].plot(t, test_acc_, 'r',label='acc_test(transfer)')\n",
    "#axis[1].set_title('accuary')\n",
    "#plt.axis([0, 100, 1, 1.1 * np.min(s), 2 * np.max(s)])\n",
    "axis[1].set_xlabel('epoch (s)')\n",
    "axis[1].set_ylabel('acc')\n",
    "#plt.ylabel('loss(s)')\n",
    "#plt.title('transfer learning based on AlexNet')\n",
    "\n",
    "fig.suptitle('transfer learning based on resnet 50 with mmd adapter')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "amazon --> webcam: max correct: 2804, accuracy 99.54%\n",
      "\n",
      "amazon --> webcam: max correct: 593, accuracy 74.59%\n",
      "\n",
      "amazon --> webcam: max correct: 588, accuracy 73.96%\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#train, valid, test acc\n",
    "test(model, source_loader)\n",
    "test(model, target_train_loader)\n",
    "test(model, target_test_loader)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
